{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESMA 4016\n",
    "### Random Forest con las libreria H20  y scikit-learn\n",
    "#### Edgar Acuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>1 hour 59 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/La_Paz</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.18.0.6</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>25 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_edgar2017_9rszyt</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.578 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.13 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O cluster uptime:         1 hour 59 mins\n",
       "H2O cluster timezone:       America/La_Paz\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.18.0.6\n",
       "H2O cluster version age:    25 days\n",
       "H2O cluster name:           H2O_from_python_edgar2017_9rszyt\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.578 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             2.7.13 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import graphviz\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "h2o.init()\n",
    "h2o.no_progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I- Aplicando Random Forest a Diabetes usando H20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94921875\n"
     ]
    }
   ],
   "source": [
    "diabetes = h2o.import_file(\"https://academic.uprm.edu/eacuna/diabetes.dat\")\n",
    "myx=['C1','C2','C3','C4','C5','C6','C7','C8']\n",
    "diabetes['C9']=diabetes['C9'].asfactor()\n",
    "myy=\"C9\"\n",
    "# Create test/train split\n",
    "#train, test = vehicle.split_frame(ratios=[0.75], seed=1)\n",
    "model=H2ORandomForestEstimator(ntrees=50,nfolds=10,max_depth=10)\n",
    "model.train(myx, myy, training_frame = diabetes)\n",
    "y_pred=model.predict(diabetes)\n",
    "print (y_pred['predict']==diabetes['C9']).sum()/float(len(diabetes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0418014868998\n",
      "RMSE: 0.204454119303\n",
      "LogLoss: 0.185780367692\n",
      "Mean Per-Class Error: 0.00973134328358\n",
      "AUC: 0.999399253731\n",
      "Gini: 0.998798507463\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.421681493521: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>494.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.012</td>\n",
       "<td> (6.0/500.0)</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>2.0</td>\n",
       "<td>266.0</td>\n",
       "<td>0.0075</td>\n",
       "<td> (2.0/268.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>496.0</td>\n",
       "<td>272.0</td>\n",
       "<td>0.0104</td>\n",
       "<td> (8.0/768.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       1    2    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "1      494  6    0.012    (6.0/500.0)\n",
       "2      2    266  0.0075   (2.0/268.0)\n",
       "Total  496  272  0.0104   (8.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4216815</td>\n",
       "<td>0.9851852</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4216815</td>\n",
       "<td>0.9895833</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4790862</td>\n",
       "<td>0.9916413</td>\n",
       "<td>173.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4790862</td>\n",
       "<td>0.9895833</td>\n",
       "<td>173.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9842231</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3328830</td>\n",
       "<td>1.0</td>\n",
       "<td>202.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9842231</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4216815</td>\n",
       "<td>0.9772175</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4279633</td>\n",
       "<td>0.9888060</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4216815</td>\n",
       "<td>0.9902687</td>\n",
       "<td>183.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.421681     0.985185  183\n",
       "max f2                       0.421681     0.989583  183\n",
       "max f0point5                 0.479086     0.991641  173\n",
       "max accuracy                 0.479086     0.989583  173\n",
       "max precision                0.984223     1         0\n",
       "max recall                   0.332883     1         202\n",
       "max specificity              0.984223     1         0\n",
       "max absolute_mcc             0.421681     0.977217  183\n",
       "max min_per_class_accuracy   0.427963     0.988806  181\n",
       "max mean_per_class_accuracy  0.421681     0.990269  183"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.90 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104167</td>\n",
       "<td>0.9465067</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0298507</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9372074</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0597015</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.9223724</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0895522</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0403646</td>\n",
       "<td>0.9126778</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261194</td>\n",
       "<td>0.1156716</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0507812</td>\n",
       "<td>0.9058826</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.1455224</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1015625</td>\n",
       "<td>0.8680000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1455224</td>\n",
       "<td>0.2910448</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510417</td>\n",
       "<td>0.8222099</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1417910</td>\n",
       "<td>0.4328358</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005208</td>\n",
       "<td>0.7633750</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1417910</td>\n",
       "<td>0.5746269</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3007812</td>\n",
       "<td>0.6289544</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2873134</td>\n",
       "<td>0.8619403</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3997396</td>\n",
       "<td>0.3093613</td>\n",
       "<td>1.3951296</td>\n",
       "<td>2.5016287</td>\n",
       "<td>0.4868421</td>\n",
       "<td>0.8729642</td>\n",
       "<td>0.1380597</td>\n",
       "<td>1.0</td>\n",
       "<td>39.5129615</td>\n",
       "<td>150.1628664</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1952408</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6979167</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6002604</td>\n",
       "<td>0.1253260</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6659436</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5813449</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5943601</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6992188</td>\n",
       "<td>0.0794770</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4301676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4990689</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0167598</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7994792</td>\n",
       "<td>0.0403430</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2508143</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4364821</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0814332</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8997396</td>\n",
       "<td>0.0099736</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1114327</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3878437</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1432706</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3489583</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  --------------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0104167                   0.946507           2.86567  2.86567            1                1                           0.0298507       0.0298507                  186.567  186.567\n",
       "    2        0.0208333                   0.937207           2.86567  2.86567            1                1                           0.0298507       0.0597015                  186.567  186.567\n",
       "    3        0.03125                     0.922372           2.86567  2.86567            1                1                           0.0298507       0.0895522                  186.567  186.567\n",
       "    4        0.0403646                   0.912678           2.86567  2.86567            1                1                           0.0261194       0.115672                   186.567  186.567\n",
       "    5        0.0507812                   0.905883           2.86567  2.86567            1                1                           0.0298507       0.145522                   186.567  186.567\n",
       "    6        0.101562                    0.868              2.86567  2.86567            1                1                           0.145522        0.291045                   186.567  186.567\n",
       "    7        0.151042                    0.82221            2.86567  2.86567            1                1                           0.141791        0.432836                   186.567  186.567\n",
       "    8        0.200521                    0.763375           2.86567  2.86567            1                1                           0.141791        0.574627                   186.567  186.567\n",
       "    9        0.300781                    0.628954           2.86567  2.86567            1                1                           0.287313        0.86194                    186.567  186.567\n",
       "    10       0.39974                     0.309361           1.39513  2.50163            0.486842         0.872964                    0.13806         1                          39.513   150.163\n",
       "    11       0.5                         0.195241           0        2                  0                0.697917                    0               1                          -100     100\n",
       "    12       0.60026                     0.125326           0        1.66594            0                0.581345                    0               1                          -100     66.5944\n",
       "    13       0.699219                    0.079477           0        1.43017            0                0.499069                    0               1                          -100     43.0168\n",
       "    14       0.799479                    0.040343           0        1.25081            0                0.436482                    0               1                          -100     25.0814\n",
       "    15       0.89974                     0.00997362         0        1.11143            0                0.387844                    0               1                          -100     11.1433\n",
       "    16       1                           0                  0        1                  0                0.348958                    0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_performance(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_model_python_1525969846733_1104\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0954106658468\n",
      "RMSE: 0.308886169724\n",
      "LogLoss: 0.317328124574\n",
      "Mean Per-Class Error: 0.171884777922\n",
      "AUC: 0.915245087539\n",
      "Gini: 0.830490175078\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.392428731884: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>22074.0</td>\n",
       "<td>2646.0</td>\n",
       "<td>0.107</td>\n",
       "<td> (2646.0/24720.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>2085.0</td>\n",
       "<td>5756.0</td>\n",
       "<td>0.2659</td>\n",
       "<td> (2085.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>24159.0</td>\n",
       "<td>8402.0</td>\n",
       "<td>0.1453</td>\n",
       "<td> (4731.0/32561.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  ----------------\n",
       "<=50K  22074    2646    0.107    (2646.0/24720.0)\n",
       ">50K   2085     5756    0.2659   (2085.0/7841.0)\n",
       "Total  24159    8402    0.1453   (4731.0/32561.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3924287</td>\n",
       "<td>0.7087361</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1554026</td>\n",
       "<td>0.7903656</td>\n",
       "<td>308.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6246580</td>\n",
       "<td>0.7462044</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5208434</td>\n",
       "<td>0.8648076</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9962364</td>\n",
       "<td>0.9979381</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000153</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999238</td>\n",
       "<td>0.9999595</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4500456</td>\n",
       "<td>0.6173835</td>\n",
       "<td>184.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2935780</td>\n",
       "<td>0.8268078</td>\n",
       "<td>248.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2857187</td>\n",
       "<td>0.8281152</td>\n",
       "<td>251.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.392429     0.708736  206\n",
       "max f2                       0.155403     0.790366  308\n",
       "max f0point5                 0.624658     0.746204  125\n",
       "max accuracy                 0.520843     0.864808  158\n",
       "max precision                0.996236     0.997938  2\n",
       "max recall                   1.5254e-05   1         399\n",
       "max specificity              0.999924     0.99996   0\n",
       "max absolute_mcc             0.450046     0.617383  184\n",
       "max min_per_class_accuracy   0.293578     0.826808  248\n",
       "max mean_per_class_accuracy  0.285719     0.828115  251"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 24.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9992745</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9875952</td>\n",
       "<td>4.1144444</td>\n",
       "<td>4.1335518</td>\n",
       "<td>0.9907975</td>\n",
       "<td>0.9953988</td>\n",
       "<td>0.0411937</td>\n",
       "<td>0.0827701</td>\n",
       "<td>311.4444445</td>\n",
       "<td>313.3551772</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300666</td>\n",
       "<td>0.9677419</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1399339</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969356</td>\n",
       "<td>0.0417039</td>\n",
       "<td>0.1244739</td>\n",
       "<td>315.2659100</td>\n",
       "<td>313.9933893</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9414885</td>\n",
       "<td>4.0757580</td>\n",
       "<td>4.1239761</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9930929</td>\n",
       "<td>0.0405561</td>\n",
       "<td>0.1650300</td>\n",
       "<td>307.5758005</td>\n",
       "<td>312.3976113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9102564</td>\n",
       "<td>3.8978947</td>\n",
       "<td>4.0787321</td>\n",
       "<td>0.9386503</td>\n",
       "<td>0.9821977</td>\n",
       "<td>0.0390256</td>\n",
       "<td>0.2040556</td>\n",
       "<td>289.7894738</td>\n",
       "<td>307.8732081</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7680600</td>\n",
       "<td>3.5022119</td>\n",
       "<td>3.7905605</td>\n",
       "<td>0.8433661</td>\n",
       "<td>0.9128032</td>\n",
       "<td>0.1751052</td>\n",
       "<td>0.3791608</td>\n",
       "<td>250.2211882</td>\n",
       "<td>279.0560486</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6315827</td>\n",
       "<td>2.8135031</td>\n",
       "<td>3.4649413</td>\n",
       "<td>0.6775184</td>\n",
       "<td>0.8343910</td>\n",
       "<td>0.1406708</td>\n",
       "<td>0.5198317</td>\n",
       "<td>181.3503063</td>\n",
       "<td>246.4941349</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5043899</td>\n",
       "<td>2.2803914</td>\n",
       "<td>3.1688493</td>\n",
       "<td>0.5491400</td>\n",
       "<td>0.7630892</td>\n",
       "<td>0.1140161</td>\n",
       "<td>0.6338477</td>\n",
       "<td>128.0391422</td>\n",
       "<td>216.8849336</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3308555</td>\n",
       "<td>1.5904072</td>\n",
       "<td>2.6427558</td>\n",
       "<td>0.3829853</td>\n",
       "<td>0.6364009</td>\n",
       "<td>0.1590358</td>\n",
       "<td>0.7928836</td>\n",
       "<td>59.0407217</td>\n",
       "<td>164.2755822</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.2008930</td>\n",
       "<td>1.0024539</td>\n",
       "<td>2.2327118</td>\n",
       "<td>0.2414005</td>\n",
       "<td>0.5376583</td>\n",
       "<td>0.1002423</td>\n",
       "<td>0.8931259</td>\n",
       "<td>0.2453947</td>\n",
       "<td>123.2711837</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0995909</td>\n",
       "<td>0.6058087</td>\n",
       "<td>1.9073512</td>\n",
       "<td>0.1458845</td>\n",
       "<td>0.4593084</td>\n",
       "<td>0.0605790</td>\n",
       "<td>0.9537049</td>\n",
       "<td>-39.4191317</td>\n",
       "<td>90.7351191</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0367522</td>\n",
       "<td>0.2780343</td>\n",
       "<td>1.6358123</td>\n",
       "<td>0.0669533</td>\n",
       "<td>0.3939192</td>\n",
       "<td>0.0278026</td>\n",
       "<td>0.9815075</td>\n",
       "<td>-72.1965699</td>\n",
       "<td>63.5812276</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0074059</td>\n",
       "<td>0.1058571</td>\n",
       "<td>1.4172568</td>\n",
       "<td>0.0254914</td>\n",
       "<td>0.3412890</td>\n",
       "<td>0.0105854</td>\n",
       "<td>0.9920928</td>\n",
       "<td>-89.4142904</td>\n",
       "<td>41.7256839</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0004057</td>\n",
       "<td>0.0484647</td>\n",
       "<td>1.2461644</td>\n",
       "<td>0.0116708</td>\n",
       "<td>0.3000883</td>\n",
       "<td>0.0048463</td>\n",
       "<td>0.9969392</td>\n",
       "<td>-95.1535305</td>\n",
       "<td>24.6164389</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0153046</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0036855</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.0030608</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.4695360</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010012                    0.999274           4.15266    4.15266            1                1                           0.0415763       0.0415763                  315.266   315.266\n",
       "    2        0.020024                    0.987595           4.11444    4.13355            0.990798         0.995399                    0.0411937       0.0827701                  311.444   313.355\n",
       "    3        0.0300666                   0.967742           4.15266    4.13993            1                0.996936                    0.0417039       0.124474                   315.266   313.993\n",
       "    4        0.0400172                   0.941488           4.07576    4.12398            0.981481         0.993093                    0.0405561       0.16503                    307.576   312.398\n",
       "    5        0.0500292                   0.910256           3.89789    4.07873            0.93865          0.982198                    0.0390256       0.204056                   289.789   307.873\n",
       "    6        0.100028                    0.76806            3.50221    3.79056            0.843366         0.912803                    0.175105        0.379161                   250.221   279.056\n",
       "    7        0.150026                    0.631583           2.8135     3.46494            0.677518         0.834391                    0.140671        0.519832                   181.35    246.494\n",
       "    8        0.200025                    0.50439            2.28039    3.16885            0.54914          0.763089                    0.114016        0.633848                   128.039   216.885\n",
       "    9        0.300021                    0.330855           1.59041    2.64276            0.382985         0.636401                    0.159036        0.792884                   59.0407   164.276\n",
       "    10       0.400018                    0.200893           1.00245    2.23271            0.2414           0.537658                    0.100242        0.893126                   0.245395  123.271\n",
       "    11       0.500015                    0.0995909          0.605809   1.90735            0.145885         0.459308                    0.060579        0.953705                   -39.4191  90.7351\n",
       "    12       0.600012                    0.0367522          0.278034   1.63581            0.0669533        0.393919                    0.0278026       0.981507                   -72.1966  63.5812\n",
       "    13       0.700009                    0.00740589         0.105857   1.41726            0.0254914        0.341289                    0.0105854       0.992093                   -89.4143  41.7257\n",
       "    14       0.800006                    0.000405673        0.0484647  1.24616            0.0116708        0.300088                    0.00484632      0.996939                   -95.1535  24.6164\n",
       "    15       1                           0                  0.0153046  1                  0.0036855        0.24081                     0.00306083      1                          -98.4695  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0944866573284\n",
      "RMSE: 0.307386820356\n",
      "LogLoss: 0.307497343154\n",
      "Mean Per-Class Error: 0.168600482011\n",
      "AUC: 0.91708573596\n",
      "Gini: 0.83417147192\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.336857105791: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>21315.0</td>\n",
       "<td>3405.0</td>\n",
       "<td>0.1377</td>\n",
       "<td> (3405.0/24720.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>1608.0</td>\n",
       "<td>6233.0</td>\n",
       "<td>0.2051</td>\n",
       "<td> (1608.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>22923.0</td>\n",
       "<td>9638.0</td>\n",
       "<td>0.154</td>\n",
       "<td> (5013.0/32561.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  ----------------\n",
       "<=50K  21315    3405    0.1377   (3405.0/24720.0)\n",
       ">50K   1608     6233    0.2051   (1608.0/7841.0)\n",
       "Total  22923    9638    0.154    (5013.0/32561.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3368571</td>\n",
       "<td>0.7131987</td>\n",
       "<td>229.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1477156</td>\n",
       "<td>0.7948373</td>\n",
       "<td>310.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6608986</td>\n",
       "<td>0.7479615</td>\n",
       "<td>114.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5142757</td>\n",
       "<td>0.8655447</td>\n",
       "<td>160.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9996131</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000351</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9996131</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4199436</td>\n",
       "<td>0.6202203</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2911720</td>\n",
       "<td>0.8298544</td>\n",
       "<td>248.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3100314</td>\n",
       "<td>0.8313995</td>\n",
       "<td>240.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.336857     0.713199  229\n",
       "max f2                       0.147716     0.794837  310\n",
       "max f0point5                 0.660899     0.747962  114\n",
       "max accuracy                 0.514276     0.865545  160\n",
       "max precision                0.999613     1         0\n",
       "max recall                   3.50903e-05  1         399\n",
       "max specificity              0.999613     1         0\n",
       "max absolute_mcc             0.419944     0.62022   195\n",
       "max min_per_class_accuracy   0.291172     0.829854  248\n",
       "max mean_per_class_accuracy  0.310031     0.8314    240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 24.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9939895</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9830000</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1462900</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9984663</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.0830251</td>\n",
       "<td>313.9920882</td>\n",
       "<td>314.6289991</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300974</td>\n",
       "<td>0.965</td>\n",
       "<td>4.1273380</td>\n",
       "<td>4.1399469</td>\n",
       "<td>0.9939024</td>\n",
       "<td>0.9969388</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.1246015</td>\n",
       "<td>312.7338008</td>\n",
       "<td>313.9946878</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9399286</td>\n",
       "<td>4.1012330</td>\n",
       "<td>4.1303501</td>\n",
       "<td>0.9876161</td>\n",
       "<td>0.9946278</td>\n",
       "<td>0.0406836</td>\n",
       "<td>0.1652850</td>\n",
       "<td>310.1232981</td>\n",
       "<td>313.0350110</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.91</td>\n",
       "<td>3.9361094</td>\n",
       "<td>4.0914781</td>\n",
       "<td>0.9478528</td>\n",
       "<td>0.9852670</td>\n",
       "<td>0.0394082</td>\n",
       "<td>0.2046933</td>\n",
       "<td>293.6109392</td>\n",
       "<td>309.1478118</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7624119</td>\n",
       "<td>3.4690518</td>\n",
       "<td>3.7803605</td>\n",
       "<td>0.8353808</td>\n",
       "<td>0.9103469</td>\n",
       "<td>0.1734473</td>\n",
       "<td>0.3781405</td>\n",
       "<td>246.9051828</td>\n",
       "<td>278.0360525</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6281945</td>\n",
       "<td>2.8772724</td>\n",
       "<td>3.4793928</td>\n",
       "<td>0.6928747</td>\n",
       "<td>0.8378710</td>\n",
       "<td>0.1438592</td>\n",
       "<td>0.5219997</td>\n",
       "<td>187.7272398</td>\n",
       "<td>247.9392773</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5023187</td>\n",
       "<td>2.2625360</td>\n",
       "<td>3.1752253</td>\n",
       "<td>0.5448403</td>\n",
       "<td>0.7646246</td>\n",
       "<td>0.1131233</td>\n",
       "<td>0.6351231</td>\n",
       "<td>126.2536008</td>\n",
       "<td>217.5225290</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3300000</td>\n",
       "<td>1.6426981</td>\n",
       "<td>2.6644352</td>\n",
       "<td>0.3955774</td>\n",
       "<td>0.6416215</td>\n",
       "<td>0.1642648</td>\n",
       "<td>0.7993878</td>\n",
       "<td>64.2698071</td>\n",
       "<td>166.4435176</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.2011260</td>\n",
       "<td>0.9514385</td>\n",
       "<td>2.2362189</td>\n",
       "<td>0.2291155</td>\n",
       "<td>0.5385029</td>\n",
       "<td>0.0951409</td>\n",
       "<td>0.8945288</td>\n",
       "<td>-4.8561521</td>\n",
       "<td>123.6218881</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.1009743</td>\n",
       "<td>0.6160118</td>\n",
       "<td>1.9121974</td>\n",
       "<td>0.1483415</td>\n",
       "<td>0.4604754</td>\n",
       "<td>0.0615993</td>\n",
       "<td>0.9561280</td>\n",
       "<td>-38.3988223</td>\n",
       "<td>91.2197363</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6001966</td>\n",
       "<td>0.04</td>\n",
       "<td>0.2507890</td>\n",
       "<td>1.6348851</td>\n",
       "<td>0.0603924</td>\n",
       "<td>0.3936960</td>\n",
       "<td>0.0251243</td>\n",
       "<td>0.9812524</td>\n",
       "<td>-74.9210962</td>\n",
       "<td>63.4885080</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0117609</td>\n",
       "<td>0.1034970</td>\n",
       "<td>1.4165281</td>\n",
       "<td>0.0249231</td>\n",
       "<td>0.3411135</td>\n",
       "<td>0.0103303</td>\n",
       "<td>0.9915827</td>\n",
       "<td>-89.6502958</td>\n",
       "<td>41.6528079</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0013786</td>\n",
       "<td>0.0599432</td>\n",
       "<td>1.2469615</td>\n",
       "<td>0.0144349</td>\n",
       "<td>0.3002802</td>\n",
       "<td>0.0059941</td>\n",
       "<td>0.9975768</td>\n",
       "<td>-94.0056825</td>\n",
       "<td>24.6961476</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0121162</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0029177</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.0024232</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.7883826</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010012                    0.993989           4.15266    4.15266            1                1                           0.0415763       0.0415763                  315.266   315.266\n",
       "    2        0.020024                    0.983              4.13992    4.14629            0.996933         0.998466                    0.0414488       0.0830251                  313.992   314.629\n",
       "    3        0.0300974                   0.965              4.12734    4.13995            0.993902         0.996939                    0.0415763       0.124601                   312.734   313.995\n",
       "    4        0.0400172                   0.939929           4.10123    4.13035            0.987616         0.994628                    0.0406836       0.165285                   310.123   313.035\n",
       "    5        0.0500292                   0.91               3.93611    4.09148            0.947853         0.985267                    0.0394082       0.204693                   293.611   309.148\n",
       "    6        0.100028                    0.762412           3.46905    3.78036            0.835381         0.910347                    0.173447        0.378141                   246.905   278.036\n",
       "    7        0.150026                    0.628195           2.87727    3.47939            0.692875         0.837871                    0.143859        0.522                      187.727   247.939\n",
       "    8        0.200025                    0.502319           2.26254    3.17523            0.54484          0.764625                    0.113123        0.635123                   126.254   217.523\n",
       "    9        0.300021                    0.33               1.6427     2.66444            0.395577         0.641621                    0.164265        0.799388                   64.2698   166.444\n",
       "    10       0.400018                    0.201126           0.951438   2.23622            0.229115         0.538503                    0.0951409       0.894529                   -4.85615  123.622\n",
       "    11       0.500015                    0.100974           0.616012   1.9122             0.148342         0.460475                    0.0615993       0.956128                   -38.3988  91.2197\n",
       "    12       0.600197                    0.04               0.250789   1.63489            0.0603924        0.393696                    0.0251243       0.981252                   -74.9211  63.4885\n",
       "    13       0.700009                    0.0117609          0.103497   1.41653            0.0249231        0.341113                    0.0103303       0.991583                   -89.6503  41.6528\n",
       "    14       0.800006                    0.00137857         0.0599432  1.24696            0.0144349        0.30028                     0.00599413      0.997577                   -94.0057  24.6961\n",
       "    15       1                           0                  0.0121162  1                  0.00291769       0.24081                     0.00242316      1                          -98.7884  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.8557172</td>\n",
       "<td>0.0056866</td>\n",
       "<td>0.8488665</td>\n",
       "<td>0.8566108</td>\n",
       "<td>0.8481207</td>\n",
       "<td>0.8482972</td>\n",
       "<td>0.8681931</td>\n",
       "<td>0.8600724</td>\n",
       "<td>0.8444109</td>\n",
       "<td>0.8532724</td>\n",
       "<td>0.8616862</td>\n",
       "<td>0.8676425</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9172029</td>\n",
       "<td>0.0043945</td>\n",
       "<td>0.906693</td>\n",
       "<td>0.9177668</td>\n",
       "<td>0.9113072</td>\n",
       "<td>0.9183915</td>\n",
       "<td>0.9313124</td>\n",
       "<td>0.9200370</td>\n",
       "<td>0.9165676</td>\n",
       "<td>0.9124453</td>\n",
       "<td>0.9172846</td>\n",
       "<td>0.9202243</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1442827</td>\n",
       "<td>0.0056866</td>\n",
       "<td>0.1511335</td>\n",
       "<td>0.1433892</td>\n",
       "<td>0.1518792</td>\n",
       "<td>0.1517028</td>\n",
       "<td>0.1318069</td>\n",
       "<td>0.1399276</td>\n",
       "<td>0.1555891</td>\n",
       "<td>0.1467276</td>\n",
       "<td>0.1383138</td>\n",
       "<td>0.1323575</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>469.8</td>\n",
       "<td>19.156721</td>\n",
       "<td>480.0</td>\n",
       "<td>462.0</td>\n",
       "<td>493.0</td>\n",
       "<td>490.0</td>\n",
       "<td>426.0</td>\n",
       "<td>464.0</td>\n",
       "<td>515.0</td>\n",
       "<td>482.0</td>\n",
       "<td>461.0</td>\n",
       "<td>425.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6944455</td>\n",
       "<td>0.0116775</td>\n",
       "<td>0.6724684</td>\n",
       "<td>0.6969402</td>\n",
       "<td>0.6753277</td>\n",
       "<td>0.6890536</td>\n",
       "<td>0.6974323</td>\n",
       "<td>0.6997299</td>\n",
       "<td>0.6737811</td>\n",
       "<td>0.7000238</td>\n",
       "<td>0.7252263</td>\n",
       "<td>0.7144716</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7172135</td>\n",
       "<td>0.0074082</td>\n",
       "<td>0.7125748</td>\n",
       "<td>0.7130435</td>\n",
       "<td>0.7006679</td>\n",
       "<td>0.7206385</td>\n",
       "<td>0.7389706</td>\n",
       "<td>0.7107232</td>\n",
       "<td>0.7143649</td>\n",
       "<td>0.7096385</td>\n",
       "<td>0.7305669</td>\n",
       "<td>0.7209455</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7421954</td>\n",
       "<td>0.0144221</td>\n",
       "<td>0.7577687</td>\n",
       "<td>0.7299085</td>\n",
       "<td>0.7279838</td>\n",
       "<td>0.7552581</td>\n",
       "<td>0.7857701</td>\n",
       "<td>0.7220674</td>\n",
       "<td>0.7601511</td>\n",
       "<td>0.7195211</td>\n",
       "<td>0.7359868</td>\n",
       "<td>0.7275377</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>4.157928</td>\n",
       "<td>0.0945320</td>\n",
       "<td>4.2234044</td>\n",
       "<td>4.162791</td>\n",
       "<td>4.2046633</td>\n",
       "<td>3.9876542</td>\n",
       "<td>4.397279</td>\n",
       "<td>4.2458386</td>\n",
       "<td>4.081381</td>\n",
       "<td>4.0505548</td>\n",
       "<td>3.9443786</td>\n",
       "<td>4.2813334</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.3075063</td>\n",
       "<td>0.0129593</td>\n",
       "<td>0.3455034</td>\n",
       "<td>0.2983691</td>\n",
       "<td>0.3146811</td>\n",
       "<td>0.3021318</td>\n",
       "<td>0.2789586</td>\n",
       "<td>0.2910806</td>\n",
       "<td>0.3203061</td>\n",
       "<td>0.3101744</td>\n",
       "<td>0.3226586</td>\n",
       "<td>0.2911997</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2397286</td>\n",
       "<td>0.0222916</td>\n",
       "<td>0.2087766</td>\n",
       "<td>0.2583979</td>\n",
       "<td>0.2525907</td>\n",
       "<td>0.2197531</td>\n",
       "<td>0.1795918</td>\n",
       "<td>0.2701665</td>\n",
       "<td>0.2059186</td>\n",
       "<td>0.2737361</td>\n",
       "<td>0.2603550</td>\n",
       "<td>0.268</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.6233020</td>\n",
       "<td>0.0106780</td>\n",
       "<td>0.6170207</td>\n",
       "<td>0.6184740</td>\n",
       "<td>0.6015562</td>\n",
       "<td>0.6207566</td>\n",
       "<td>0.6577529</td>\n",
       "<td>0.6188925</td>\n",
       "<td>0.6147616</td>\n",
       "<td>0.6118274</td>\n",
       "<td>0.6376354</td>\n",
       "<td>0.6343433</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8231641</td>\n",
       "<td>0.0077941</td>\n",
       "<td>0.8289863</td>\n",
       "<td>0.817288</td>\n",
       "<td>0.8134783</td>\n",
       "<td>0.8256606</td>\n",
       "<td>0.8513334</td>\n",
       "<td>0.8150154</td>\n",
       "<td>0.8274128</td>\n",
       "<td>0.8105854</td>\n",
       "<td>0.8213900</td>\n",
       "<td>0.8204901</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1768360</td>\n",
       "<td>0.0077941</td>\n",
       "<td>0.1710137</td>\n",
       "<td>0.1827120</td>\n",
       "<td>0.1865217</td>\n",
       "<td>0.1743394</td>\n",
       "<td>0.1486666</td>\n",
       "<td>0.1849846</td>\n",
       "<td>0.1725872</td>\n",
       "<td>0.1894145</td>\n",
       "<td>0.17861</td>\n",
       "<td>0.1795100</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0944789</td>\n",
       "<td>0.0027157</td>\n",
       "<td>0.0975584</td>\n",
       "<td>0.0947295</td>\n",
       "<td>0.0972577</td>\n",
       "<td>0.0962749</td>\n",
       "<td>0.0846985</td>\n",
       "<td>0.0929907</td>\n",
       "<td>0.0953042</td>\n",
       "<td>0.0984002</td>\n",
       "<td>0.0962489</td>\n",
       "<td>0.0913261</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6803380</td>\n",
       "<td>0.0167339</td>\n",
       "<td>0.6481481</td>\n",
       "<td>0.6866029</td>\n",
       "<td>0.6594286</td>\n",
       "<td>0.6694915</td>\n",
       "<td>0.6722408</td>\n",
       "<td>0.6925881</td>\n",
       "<td>0.6491935</td>\n",
       "<td>0.6937574</td>\n",
       "<td>0.721709</td>\n",
       "<td>0.7102199</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.4830466</td>\n",
       "<td>0.0110002</td>\n",
       "<td>0.4601474</td>\n",
       "<td>0.4809804</td>\n",
       "<td>0.4634575</td>\n",
       "<td>0.4875900</td>\n",
       "<td>0.5179275</td>\n",
       "<td>0.4835364</td>\n",
       "<td>0.4847942</td>\n",
       "<td>0.4707678</td>\n",
       "<td>0.4914202</td>\n",
       "<td>0.4898443</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7602714</td>\n",
       "<td>0.0222916</td>\n",
       "<td>0.7912234</td>\n",
       "<td>0.7416021</td>\n",
       "<td>0.7474093</td>\n",
       "<td>0.7802469</td>\n",
       "<td>0.8204082</td>\n",
       "<td>0.7298335</td>\n",
       "<td>0.7940814</td>\n",
       "<td>0.7262639</td>\n",
       "<td>0.7396449</td>\n",
       "<td>0.732</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3073086</td>\n",
       "<td>0.0044893</td>\n",
       "<td>0.3123434</td>\n",
       "<td>0.3077815</td>\n",
       "<td>0.3118617</td>\n",
       "<td>0.3102819</td>\n",
       "<td>0.2910300</td>\n",
       "<td>0.3049438</td>\n",
       "<td>0.3087137</td>\n",
       "<td>0.3136881</td>\n",
       "<td>0.31024</td>\n",
       "<td>0.3022021</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8860567</td>\n",
       "<td>0.0110409</td>\n",
       "<td>0.8667492</td>\n",
       "<td>0.8929738</td>\n",
       "<td>0.8795473</td>\n",
       "<td>0.8710744</td>\n",
       "<td>0.8822587</td>\n",
       "<td>0.9001973</td>\n",
       "<td>0.8607443</td>\n",
       "<td>0.8949071</td>\n",
       "<td>0.9031351</td>\n",
       "<td>0.9089801</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "accuracy                 0.855717   0.00568664  0.848866      0.856611      0.848121      0.848297      0.868193      0.860072      0.844411      0.853272      0.861686      0.867642\n",
       "auc                      0.917203   0.0043945   0.906693      0.917767      0.911307      0.918391      0.931312      0.920037      0.916568      0.912445      0.917285      0.920224\n",
       "err                      0.144283   0.00568664  0.151134      0.143389      0.151879      0.151703      0.131807      0.139928      0.155589      0.146728      0.138314      0.132358\n",
       "err_count                469.8      19.1567     480           462           493           490           426           464           515           482           461           425\n",
       "f0point5                 0.694446   0.0116775   0.672468      0.69694       0.675328      0.689054      0.697432      0.69973       0.673781      0.700024      0.725226      0.714472\n",
       "f1                       0.717213   0.00740819  0.712575      0.713043      0.700668      0.720638      0.738971      0.710723      0.714365      0.709639      0.730567      0.720946\n",
       "f2                       0.742195   0.0144221   0.757769      0.729908      0.727984      0.755258      0.78577       0.722067      0.760151      0.719521      0.735987      0.727538\n",
       "lift_top_group           4.15793    0.094532    4.2234        4.16279       4.20466       3.98765       4.39728       4.24584       4.08138       4.05055       3.94438       4.28133\n",
       "logloss                  0.307506   0.0129593   0.345503      0.298369      0.314681      0.302132      0.278959      0.291081      0.320306      0.310174      0.322659      0.2912\n",
       "max_per_class_error      0.239729   0.0222916   0.208777      0.258398      0.252591      0.219753      0.179592      0.270166      0.205919      0.273736      0.260355      0.268\n",
       "mcc                      0.623302   0.010678    0.617021      0.618474      0.601556      0.620757      0.657753      0.618892      0.614762      0.611827      0.637635      0.634343\n",
       "mean_per_class_accuracy  0.823164   0.0077941   0.828986      0.817288      0.813478      0.825661      0.851333      0.815015      0.827413      0.810585      0.82139       0.82049\n",
       "mean_per_class_error     0.176836   0.0077941   0.171014      0.182712      0.186522      0.174339      0.148667      0.184985      0.172587      0.189415      0.17861       0.17951\n",
       "mse                      0.0944789  0.00271565  0.0975584     0.0947295     0.0972577     0.0962749     0.0846985     0.0929907     0.0953042     0.0984002     0.0962489     0.0913261\n",
       "precision                0.680338   0.0167339   0.648148      0.686603      0.659429      0.669492      0.672241      0.692588      0.649193      0.693757      0.721709      0.71022\n",
       "r2                       0.483047   0.0110002   0.460147      0.48098       0.463458      0.48759       0.517927      0.483536      0.484794      0.470768      0.49142       0.489844\n",
       "recall                   0.760271   0.0222916   0.791223      0.741602      0.747409      0.780247      0.820408      0.729834      0.794081      0.726264      0.739645      0.732\n",
       "rmse                     0.307309   0.00448927  0.312343      0.307782      0.311862      0.310282      0.29103       0.304944      0.308714      0.313688      0.31024       0.302202\n",
       "specificity              0.886057   0.0110409   0.866749      0.892974      0.879547      0.871074      0.882259      0.900197      0.860744      0.894907      0.903135      0.90898"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.156 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.201 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3796713</td>\n",
       "<td>3.4188301</td>\n",
       "<td>0.8155289</td>\n",
       "<td>2.8350811</td>\n",
       "<td>0.1873739</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.242 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3764685</td>\n",
       "<td>3.0939931</td>\n",
       "<td>0.8164008</td>\n",
       "<td>2.9296968</td>\n",
       "<td>0.1881883</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.283 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.3667262</td>\n",
       "<td>2.5705995</td>\n",
       "<td>0.8335322</td>\n",
       "<td>3.0308145</td>\n",
       "<td>0.1816686</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.328 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.3591954</td>\n",
       "<td>2.1754763</td>\n",
       "<td>0.8448378</td>\n",
       "<td>3.1497184</td>\n",
       "<td>0.1785335</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:49</td>\n",
       "<td>56.925 sec</td>\n",
       "<td>66.0</td>\n",
       "<td>0.3105401</td>\n",
       "<td>0.3348466</td>\n",
       "<td>0.9131652</td>\n",
       "<td>4.1441670</td>\n",
       "<td>0.1490126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:49</td>\n",
       "<td>56.988 sec</td>\n",
       "<td>67.0</td>\n",
       "<td>0.3105157</td>\n",
       "<td>0.3348186</td>\n",
       "<td>0.9131317</td>\n",
       "<td>4.1440436</td>\n",
       "<td>0.1485519</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:50</td>\n",
       "<td>57.051 sec</td>\n",
       "<td>68.0</td>\n",
       "<td>0.3104649</td>\n",
       "<td>0.3347822</td>\n",
       "<td>0.9131897</td>\n",
       "<td>4.1438982</td>\n",
       "<td>0.1475999</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:50</td>\n",
       "<td>57.107 sec</td>\n",
       "<td>69.0</td>\n",
       "<td>0.3103963</td>\n",
       "<td>0.3337514</td>\n",
       "<td>0.9132453</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1409969</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:51</td>\n",
       "<td>58.301 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.3088862</td>\n",
       "<td>0.3173281</td>\n",
       "<td>0.9152451</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1452965</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "     2018-05-10 14:34:46  53.156 sec  0.0                nan              nan                 nan             nan              nan\n",
       "     2018-05-10 14:34:46  53.201 sec  1.0                0.379671278305   3.4188300603        0.815528878936  2.83508106742    0.187373907196\n",
       "     2018-05-10 14:34:46  53.242 sec  2.0                0.376468519133   3.09399309253       0.816400815685  2.92969676599    0.188188290734\n",
       "     2018-05-10 14:34:46  53.283 sec  3.0                0.36672621347    2.57059945443       0.833532213426  3.03081449927    0.181668586474\n",
       "     2018-05-10 14:34:46  53.328 sec  4.0                0.359195390388   2.17547627621       0.844837764203  3.14971844877    0.178533513929\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---\n",
       "     2018-05-10 14:34:49  56.925 sec  66.0               0.310540061274   0.334846625121      0.913165213431  4.14416695421    0.149012622462\n",
       "     2018-05-10 14:34:49  56.988 sec  67.0               0.310515660391   0.334818590005      0.913131699444  4.14404362429    0.14855194865\n",
       "     2018-05-10 14:34:50  57.051 sec  68.0               0.310464949836   0.334782236896      0.913189698865  4.14389821543    0.147599889438\n",
       "     2018-05-10 14:34:50  57.107 sec  69.0               0.31039634959    0.333751370877      0.913245265737  4.1526590996     0.14099689813\n",
       "     2018-05-10 14:34:51  58.301 sec  100.0              0.308886169724   0.317328124574      0.915245087539  4.1526590996     0.145296520377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C8</td>\n",
       "<td>52661.3164062</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1695343</td></tr>\n",
       "<tr><td>C11</td>\n",
       "<td>42302.8593750</td>\n",
       "<td>0.8033005</td>\n",
       "<td>0.1361869</td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>36100.9257812</td>\n",
       "<td>0.6855303</td>\n",
       "<td>0.1162209</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>28606.3183594</td>\n",
       "<td>0.5432131</td>\n",
       "<td>0.0920932</td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>27755.6152344</td>\n",
       "<td>0.5270589</td>\n",
       "<td>0.0893545</td></tr>\n",
       "<tr><td>C5</td>\n",
       "<td>25600.5605469</td>\n",
       "<td>0.4861360</td>\n",
       "<td>0.0824167</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>23276.8378906</td>\n",
       "<td>0.4420102</td>\n",
       "<td>0.0749359</td></tr>\n",
       "<tr><td>C13</td>\n",
       "<td>18809.4824219</td>\n",
       "<td>0.3571784</td>\n",
       "<td>0.0605540</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>17458.1601562</td>\n",
       "<td>0.3315177</td>\n",
       "<td>0.0562036</td></tr>\n",
       "<tr><td>C12</td>\n",
       "<td>11310.0722656</td>\n",
       "<td>0.2147700</td>\n",
       "<td>0.0364109</td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>10894.1757812</td>\n",
       "<td>0.2068725</td>\n",
       "<td>0.0350720</td></tr>\n",
       "<tr><td>C14</td>\n",
       "<td>8426.4023438</td>\n",
       "<td>0.1600112</td>\n",
       "<td>0.0271274</td></tr>\n",
       "<tr><td>C9</td>\n",
       "<td>3719.1481934</td>\n",
       "<td>0.0706239</td>\n",
       "<td>0.0119732</td></tr>\n",
       "<tr><td>C10</td>\n",
       "<td>3701.5864258</td>\n",
       "<td>0.0702904</td>\n",
       "<td>0.0119166</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "C8          52661.3                1                    0.169534\n",
       "C11         42302.9                0.8033               0.136187\n",
       "C6          36100.9                0.68553              0.116221\n",
       "C1          28606.3                0.543213             0.0920932\n",
       "C7          27755.6                0.527059             0.0893545\n",
       "C5          25600.6                0.486136             0.0824167\n",
       "C4          23276.8                0.44201              0.0749359\n",
       "C13         18809.5                0.357178             0.060554\n",
       "C3          17458.2                0.331518             0.0562036\n",
       "C12         11310.1                0.21477              0.0364109\n",
       "C2          10894.2                0.206872             0.035072\n",
       "C14         8426.4                 0.160011             0.0271274\n",
       "C9          3719.15                0.0706239            0.0119732\n",
       "C10         3701.59                0.0702904            0.0119166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method ?.confusion_matrix of >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostrando la matrix de consusion para estimar la precision out-of-bag y por validacion crizada\n",
    "model.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHHCAYAAABtF1i4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMAIAAKwijAAAAKv+P0au6UGRtuw2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc7b6cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "variables = model._model_json['output']['variable_importances']['variable']\n",
    "y_pos = np.arange(len(variables))\n",
    "scaled_importance =model._model_json['output']['variable_importances']['scaled_importance']\n",
    "ax.barh(y_pos, scaled_importance, align='center', color='green', ecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(variables)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Scaled Importance')\n",
    "ax.set_title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segun random Forest las variables mas importantes serian plas, age y mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Random Forest  para Diabetes usando scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la Precision estimada es 0.986979166667\n"
     ]
    }
   ],
   "source": [
    "url= \"http://academic.uprm.edu/eacuna/diabetes.dat\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_table(url, names=names,header=None)\n",
    "#La variable de respuesta y debe ser binaria (0,1)\n",
    "y=data['class']-1\n",
    "X=data.iloc[:,0:8]\n",
    "clf = RandomForestClassifier(n_estimators=50,max_depth=10, oob_score=True,random_state=0)\n",
    "clf.fit(X, y)\n",
    "print \"la Precision estimada es\", clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       500\n",
      "          1       1.00      0.97      0.98       268\n",
      "\n",
      "avg / total       0.99      0.99      0.99       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tasa de precision\n",
    "predictions = clf.predict(X)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[499   1]\n",
      " [  9 259]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7421875\n"
     ]
    }
   ],
   "source": [
    "#Tasa de precision usando out-of-Bag\n",
    "print clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08178093  0.25522871  0.08433383  0.07064764  0.06914087  0.17326173\n",
      "  0.12167218  0.14393411]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nuevamente las variables mas importantes salieron plas mass y age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Random Forest para Landsat usando H2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984216459977\n",
      "\n",
      "ModelMetricsMultinomial: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.025741118164\n",
      "RMSE: 0.160440388194\n",
      "LogLoss: 0.112026858001\n",
      "Mean Per-Class Error: 0.0253718538326\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1072.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 1,072</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>477.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0041754</td>\n",
       "<td>2 / 479</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>961.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 961</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>33.0</td>\n",
       "<td>370.0</td>\n",
       "<td>0.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.1084337</td>\n",
       "<td>45 / 415</td></tr>\n",
       "<tr><td>9.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>455.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0319149</td>\n",
       "<td>15 / 470</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1030.0</td>\n",
       "<td>0.0077071</td>\n",
       "<td>8 / 1,038</td></tr>\n",
       "<tr><td>1082.0</td>\n",
       "<td>477.0</td>\n",
       "<td>996.0</td>\n",
       "<td>376.0</td>\n",
       "<td>456.0</td>\n",
       "<td>1048.0</td>\n",
       "<td>0.0157835</td>\n",
       "<td>70 / 4,435</td></tr></table></div>"
      ],
      "text/plain": [
       "1     2    3    4    5    6     Error       Rate\n",
       "----  ---  ---  ---  ---  ----  ----------  ----------\n",
       "1072  0    0    0    0    0     0           0 / 1,072\n",
       "1     477  0    0    1    0     0.00417537  2 / 479\n",
       "0     0    961  0    0    0     0           0 / 961\n",
       "0     0    33   370  0    12    0.108434    45 / 415\n",
       "9     0    0    0    455  6     0.0319149   15 / 470\n",
       "0     0    2    6    0    1030  0.00770713  8 / 1,038\n",
       "1082  477  996  376  456  1048  0.0157835   70 / 4,435"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-6 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9842165</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9997745</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9997745</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.984216\n",
       "2    0.999775\n",
       "3    0.999775\n",
       "4    1\n",
       "5    1\n",
       "6    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leyendo los datos\n",
    "datos= h2o.import_file(\"http://academic.uprm.edu/eacuna/landsat.txt\")\n",
    "myx=['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13',\n",
    "            'C14','C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26','C27',\n",
    "           'C28','C29', 'C30','C31','C32','C33','C34','C35','C36']\n",
    "datos['C37']=datos['C37'].asfactor()\n",
    "myy=\"C37\"\n",
    "model=H2ORandomForestEstimator(ntrees=50,max_depth=10,nfolds=10)\n",
    "model.train(myx, myy, training_frame = datos)\n",
    "y_pred=model.predict(datos)\n",
    "print (y_pred['predict']==datos['C37']).sum()/float(len(datos))\n",
    "model.model_performance(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_model_python_1525969846733_1104\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0954106658468\n",
      "RMSE: 0.308886169724\n",
      "LogLoss: 0.317328124574\n",
      "Mean Per-Class Error: 0.171884777922\n",
      "AUC: 0.915245087539\n",
      "Gini: 0.830490175078\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.392428731884: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>22074.0</td>\n",
       "<td>2646.0</td>\n",
       "<td>0.107</td>\n",
       "<td> (2646.0/24720.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>2085.0</td>\n",
       "<td>5756.0</td>\n",
       "<td>0.2659</td>\n",
       "<td> (2085.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>24159.0</td>\n",
       "<td>8402.0</td>\n",
       "<td>0.1453</td>\n",
       "<td> (4731.0/32561.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  ----------------\n",
       "<=50K  22074    2646    0.107    (2646.0/24720.0)\n",
       ">50K   2085     5756    0.2659   (2085.0/7841.0)\n",
       "Total  24159    8402    0.1453   (4731.0/32561.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3924287</td>\n",
       "<td>0.7087361</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1554026</td>\n",
       "<td>0.7903656</td>\n",
       "<td>308.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6246580</td>\n",
       "<td>0.7462044</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5208434</td>\n",
       "<td>0.8648076</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9962364</td>\n",
       "<td>0.9979381</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000153</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999238</td>\n",
       "<td>0.9999595</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4500456</td>\n",
       "<td>0.6173835</td>\n",
       "<td>184.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2935780</td>\n",
       "<td>0.8268078</td>\n",
       "<td>248.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2857187</td>\n",
       "<td>0.8281152</td>\n",
       "<td>251.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.392429     0.708736  206\n",
       "max f2                       0.155403     0.790366  308\n",
       "max f0point5                 0.624658     0.746204  125\n",
       "max accuracy                 0.520843     0.864808  158\n",
       "max precision                0.996236     0.997938  2\n",
       "max recall                   1.5254e-05   1         399\n",
       "max specificity              0.999924     0.99996   0\n",
       "max absolute_mcc             0.450046     0.617383  184\n",
       "max min_per_class_accuracy   0.293578     0.826808  248\n",
       "max mean_per_class_accuracy  0.285719     0.828115  251"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 24.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9992745</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9875952</td>\n",
       "<td>4.1144444</td>\n",
       "<td>4.1335518</td>\n",
       "<td>0.9907975</td>\n",
       "<td>0.9953988</td>\n",
       "<td>0.0411937</td>\n",
       "<td>0.0827701</td>\n",
       "<td>311.4444445</td>\n",
       "<td>313.3551772</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300666</td>\n",
       "<td>0.9677419</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1399339</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969356</td>\n",
       "<td>0.0417039</td>\n",
       "<td>0.1244739</td>\n",
       "<td>315.2659100</td>\n",
       "<td>313.9933893</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9414885</td>\n",
       "<td>4.0757580</td>\n",
       "<td>4.1239761</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9930929</td>\n",
       "<td>0.0405561</td>\n",
       "<td>0.1650300</td>\n",
       "<td>307.5758005</td>\n",
       "<td>312.3976113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9102564</td>\n",
       "<td>3.8978947</td>\n",
       "<td>4.0787321</td>\n",
       "<td>0.9386503</td>\n",
       "<td>0.9821977</td>\n",
       "<td>0.0390256</td>\n",
       "<td>0.2040556</td>\n",
       "<td>289.7894738</td>\n",
       "<td>307.8732081</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7680600</td>\n",
       "<td>3.5022119</td>\n",
       "<td>3.7905605</td>\n",
       "<td>0.8433661</td>\n",
       "<td>0.9128032</td>\n",
       "<td>0.1751052</td>\n",
       "<td>0.3791608</td>\n",
       "<td>250.2211882</td>\n",
       "<td>279.0560486</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6315827</td>\n",
       "<td>2.8135031</td>\n",
       "<td>3.4649413</td>\n",
       "<td>0.6775184</td>\n",
       "<td>0.8343910</td>\n",
       "<td>0.1406708</td>\n",
       "<td>0.5198317</td>\n",
       "<td>181.3503063</td>\n",
       "<td>246.4941349</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5043899</td>\n",
       "<td>2.2803914</td>\n",
       "<td>3.1688493</td>\n",
       "<td>0.5491400</td>\n",
       "<td>0.7630892</td>\n",
       "<td>0.1140161</td>\n",
       "<td>0.6338477</td>\n",
       "<td>128.0391422</td>\n",
       "<td>216.8849336</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3308555</td>\n",
       "<td>1.5904072</td>\n",
       "<td>2.6427558</td>\n",
       "<td>0.3829853</td>\n",
       "<td>0.6364009</td>\n",
       "<td>0.1590358</td>\n",
       "<td>0.7928836</td>\n",
       "<td>59.0407217</td>\n",
       "<td>164.2755822</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.2008930</td>\n",
       "<td>1.0024539</td>\n",
       "<td>2.2327118</td>\n",
       "<td>0.2414005</td>\n",
       "<td>0.5376583</td>\n",
       "<td>0.1002423</td>\n",
       "<td>0.8931259</td>\n",
       "<td>0.2453947</td>\n",
       "<td>123.2711837</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0995909</td>\n",
       "<td>0.6058087</td>\n",
       "<td>1.9073512</td>\n",
       "<td>0.1458845</td>\n",
       "<td>0.4593084</td>\n",
       "<td>0.0605790</td>\n",
       "<td>0.9537049</td>\n",
       "<td>-39.4191317</td>\n",
       "<td>90.7351191</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0367522</td>\n",
       "<td>0.2780343</td>\n",
       "<td>1.6358123</td>\n",
       "<td>0.0669533</td>\n",
       "<td>0.3939192</td>\n",
       "<td>0.0278026</td>\n",
       "<td>0.9815075</td>\n",
       "<td>-72.1965699</td>\n",
       "<td>63.5812276</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0074059</td>\n",
       "<td>0.1058571</td>\n",
       "<td>1.4172568</td>\n",
       "<td>0.0254914</td>\n",
       "<td>0.3412890</td>\n",
       "<td>0.0105854</td>\n",
       "<td>0.9920928</td>\n",
       "<td>-89.4142904</td>\n",
       "<td>41.7256839</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0004057</td>\n",
       "<td>0.0484647</td>\n",
       "<td>1.2461644</td>\n",
       "<td>0.0116708</td>\n",
       "<td>0.3000883</td>\n",
       "<td>0.0048463</td>\n",
       "<td>0.9969392</td>\n",
       "<td>-95.1535305</td>\n",
       "<td>24.6164389</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0153046</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0036855</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.0030608</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.4695360</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010012                    0.999274           4.15266    4.15266            1                1                           0.0415763       0.0415763                  315.266   315.266\n",
       "    2        0.020024                    0.987595           4.11444    4.13355            0.990798         0.995399                    0.0411937       0.0827701                  311.444   313.355\n",
       "    3        0.0300666                   0.967742           4.15266    4.13993            1                0.996936                    0.0417039       0.124474                   315.266   313.993\n",
       "    4        0.0400172                   0.941488           4.07576    4.12398            0.981481         0.993093                    0.0405561       0.16503                    307.576   312.398\n",
       "    5        0.0500292                   0.910256           3.89789    4.07873            0.93865          0.982198                    0.0390256       0.204056                   289.789   307.873\n",
       "    6        0.100028                    0.76806            3.50221    3.79056            0.843366         0.912803                    0.175105        0.379161                   250.221   279.056\n",
       "    7        0.150026                    0.631583           2.8135     3.46494            0.677518         0.834391                    0.140671        0.519832                   181.35    246.494\n",
       "    8        0.200025                    0.50439            2.28039    3.16885            0.54914          0.763089                    0.114016        0.633848                   128.039   216.885\n",
       "    9        0.300021                    0.330855           1.59041    2.64276            0.382985         0.636401                    0.159036        0.792884                   59.0407   164.276\n",
       "    10       0.400018                    0.200893           1.00245    2.23271            0.2414           0.537658                    0.100242        0.893126                   0.245395  123.271\n",
       "    11       0.500015                    0.0995909          0.605809   1.90735            0.145885         0.459308                    0.060579        0.953705                   -39.4191  90.7351\n",
       "    12       0.600012                    0.0367522          0.278034   1.63581            0.0669533        0.393919                    0.0278026       0.981507                   -72.1966  63.5812\n",
       "    13       0.700009                    0.00740589         0.105857   1.41726            0.0254914        0.341289                    0.0105854       0.992093                   -89.4143  41.7257\n",
       "    14       0.800006                    0.000405673        0.0484647  1.24616            0.0116708        0.300088                    0.00484632      0.996939                   -95.1535  24.6164\n",
       "    15       1                           0                  0.0153046  1                  0.0036855        0.24081                     0.00306083      1                          -98.4695  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0944866573284\n",
      "RMSE: 0.307386820356\n",
      "LogLoss: 0.307497343154\n",
      "Mean Per-Class Error: 0.168600482011\n",
      "AUC: 0.91708573596\n",
      "Gini: 0.83417147192\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.336857105791: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>21315.0</td>\n",
       "<td>3405.0</td>\n",
       "<td>0.1377</td>\n",
       "<td> (3405.0/24720.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>1608.0</td>\n",
       "<td>6233.0</td>\n",
       "<td>0.2051</td>\n",
       "<td> (1608.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>22923.0</td>\n",
       "<td>9638.0</td>\n",
       "<td>0.154</td>\n",
       "<td> (5013.0/32561.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  ----------------\n",
       "<=50K  21315    3405    0.1377   (3405.0/24720.0)\n",
       ">50K   1608     6233    0.2051   (1608.0/7841.0)\n",
       "Total  22923    9638    0.154    (5013.0/32561.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3368571</td>\n",
       "<td>0.7131987</td>\n",
       "<td>229.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1477156</td>\n",
       "<td>0.7948373</td>\n",
       "<td>310.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6608986</td>\n",
       "<td>0.7479615</td>\n",
       "<td>114.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5142757</td>\n",
       "<td>0.8655447</td>\n",
       "<td>160.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9996131</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000351</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9996131</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4199436</td>\n",
       "<td>0.6202203</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2911720</td>\n",
       "<td>0.8298544</td>\n",
       "<td>248.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3100314</td>\n",
       "<td>0.8313995</td>\n",
       "<td>240.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.336857     0.713199  229\n",
       "max f2                       0.147716     0.794837  310\n",
       "max f0point5                 0.660899     0.747962  114\n",
       "max accuracy                 0.514276     0.865545  160\n",
       "max precision                0.999613     1         0\n",
       "max recall                   3.50903e-05  1         399\n",
       "max specificity              0.999613     1         0\n",
       "max absolute_mcc             0.419944     0.62022   195\n",
       "max min_per_class_accuracy   0.291172     0.829854  248\n",
       "max mean_per_class_accuracy  0.310031     0.8314    240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 24.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9939895</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9830000</td>\n",
       "<td>4.1399209</td>\n",
       "<td>4.1462900</td>\n",
       "<td>0.9969325</td>\n",
       "<td>0.9984663</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.0830251</td>\n",
       "<td>313.9920882</td>\n",
       "<td>314.6289991</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300974</td>\n",
       "<td>0.965</td>\n",
       "<td>4.1273380</td>\n",
       "<td>4.1399469</td>\n",
       "<td>0.9939024</td>\n",
       "<td>0.9969388</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.1246015</td>\n",
       "<td>312.7338008</td>\n",
       "<td>313.9946878</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9399286</td>\n",
       "<td>4.1012330</td>\n",
       "<td>4.1303501</td>\n",
       "<td>0.9876161</td>\n",
       "<td>0.9946278</td>\n",
       "<td>0.0406836</td>\n",
       "<td>0.1652850</td>\n",
       "<td>310.1232981</td>\n",
       "<td>313.0350110</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.91</td>\n",
       "<td>3.9361094</td>\n",
       "<td>4.0914781</td>\n",
       "<td>0.9478528</td>\n",
       "<td>0.9852670</td>\n",
       "<td>0.0394082</td>\n",
       "<td>0.2046933</td>\n",
       "<td>293.6109392</td>\n",
       "<td>309.1478118</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.7624119</td>\n",
       "<td>3.4690518</td>\n",
       "<td>3.7803605</td>\n",
       "<td>0.8353808</td>\n",
       "<td>0.9103469</td>\n",
       "<td>0.1734473</td>\n",
       "<td>0.3781405</td>\n",
       "<td>246.9051828</td>\n",
       "<td>278.0360525</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6281945</td>\n",
       "<td>2.8772724</td>\n",
       "<td>3.4793928</td>\n",
       "<td>0.6928747</td>\n",
       "<td>0.8378710</td>\n",
       "<td>0.1438592</td>\n",
       "<td>0.5219997</td>\n",
       "<td>187.7272398</td>\n",
       "<td>247.9392773</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5023187</td>\n",
       "<td>2.2625360</td>\n",
       "<td>3.1752253</td>\n",
       "<td>0.5448403</td>\n",
       "<td>0.7646246</td>\n",
       "<td>0.1131233</td>\n",
       "<td>0.6351231</td>\n",
       "<td>126.2536008</td>\n",
       "<td>217.5225290</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3300000</td>\n",
       "<td>1.6426981</td>\n",
       "<td>2.6644352</td>\n",
       "<td>0.3955774</td>\n",
       "<td>0.6416215</td>\n",
       "<td>0.1642648</td>\n",
       "<td>0.7993878</td>\n",
       "<td>64.2698071</td>\n",
       "<td>166.4435176</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.2011260</td>\n",
       "<td>0.9514385</td>\n",
       "<td>2.2362189</td>\n",
       "<td>0.2291155</td>\n",
       "<td>0.5385029</td>\n",
       "<td>0.0951409</td>\n",
       "<td>0.8945288</td>\n",
       "<td>-4.8561521</td>\n",
       "<td>123.6218881</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.1009743</td>\n",
       "<td>0.6160118</td>\n",
       "<td>1.9121974</td>\n",
       "<td>0.1483415</td>\n",
       "<td>0.4604754</td>\n",
       "<td>0.0615993</td>\n",
       "<td>0.9561280</td>\n",
       "<td>-38.3988223</td>\n",
       "<td>91.2197363</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6001966</td>\n",
       "<td>0.04</td>\n",
       "<td>0.2507890</td>\n",
       "<td>1.6348851</td>\n",
       "<td>0.0603924</td>\n",
       "<td>0.3936960</td>\n",
       "<td>0.0251243</td>\n",
       "<td>0.9812524</td>\n",
       "<td>-74.9210962</td>\n",
       "<td>63.4885080</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0117609</td>\n",
       "<td>0.1034970</td>\n",
       "<td>1.4165281</td>\n",
       "<td>0.0249231</td>\n",
       "<td>0.3411135</td>\n",
       "<td>0.0103303</td>\n",
       "<td>0.9915827</td>\n",
       "<td>-89.6502958</td>\n",
       "<td>41.6528079</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0013786</td>\n",
       "<td>0.0599432</td>\n",
       "<td>1.2469615</td>\n",
       "<td>0.0144349</td>\n",
       "<td>0.3002802</td>\n",
       "<td>0.0059941</td>\n",
       "<td>0.9975768</td>\n",
       "<td>-94.0056825</td>\n",
       "<td>24.6961476</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0121162</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0029177</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.0024232</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.7883826</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010012                    0.993989           4.15266    4.15266            1                1                           0.0415763       0.0415763                  315.266   315.266\n",
       "    2        0.020024                    0.983              4.13992    4.14629            0.996933         0.998466                    0.0414488       0.0830251                  313.992   314.629\n",
       "    3        0.0300974                   0.965              4.12734    4.13995            0.993902         0.996939                    0.0415763       0.124601                   312.734   313.995\n",
       "    4        0.0400172                   0.939929           4.10123    4.13035            0.987616         0.994628                    0.0406836       0.165285                   310.123   313.035\n",
       "    5        0.0500292                   0.91               3.93611    4.09148            0.947853         0.985267                    0.0394082       0.204693                   293.611   309.148\n",
       "    6        0.100028                    0.762412           3.46905    3.78036            0.835381         0.910347                    0.173447        0.378141                   246.905   278.036\n",
       "    7        0.150026                    0.628195           2.87727    3.47939            0.692875         0.837871                    0.143859        0.522                      187.727   247.939\n",
       "    8        0.200025                    0.502319           2.26254    3.17523            0.54484          0.764625                    0.113123        0.635123                   126.254   217.523\n",
       "    9        0.300021                    0.33               1.6427     2.66444            0.395577         0.641621                    0.164265        0.799388                   64.2698   166.444\n",
       "    10       0.400018                    0.201126           0.951438   2.23622            0.229115         0.538503                    0.0951409       0.894529                   -4.85615  123.622\n",
       "    11       0.500015                    0.100974           0.616012   1.9122             0.148342         0.460475                    0.0615993       0.956128                   -38.3988  91.2197\n",
       "    12       0.600197                    0.04               0.250789   1.63489            0.0603924        0.393696                    0.0251243       0.981252                   -74.9211  63.4885\n",
       "    13       0.700009                    0.0117609          0.103497   1.41653            0.0249231        0.341113                    0.0103303       0.991583                   -89.6503  41.6528\n",
       "    14       0.800006                    0.00137857         0.0599432  1.24696            0.0144349        0.30028                     0.00599413      0.997577                   -94.0057  24.6961\n",
       "    15       1                           0                  0.0121162  1                  0.00291769       0.24081                     0.00242316      1                          -98.7884  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.8557172</td>\n",
       "<td>0.0056866</td>\n",
       "<td>0.8488665</td>\n",
       "<td>0.8566108</td>\n",
       "<td>0.8481207</td>\n",
       "<td>0.8482972</td>\n",
       "<td>0.8681931</td>\n",
       "<td>0.8600724</td>\n",
       "<td>0.8444109</td>\n",
       "<td>0.8532724</td>\n",
       "<td>0.8616862</td>\n",
       "<td>0.8676425</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9172029</td>\n",
       "<td>0.0043945</td>\n",
       "<td>0.906693</td>\n",
       "<td>0.9177668</td>\n",
       "<td>0.9113072</td>\n",
       "<td>0.9183915</td>\n",
       "<td>0.9313124</td>\n",
       "<td>0.9200370</td>\n",
       "<td>0.9165676</td>\n",
       "<td>0.9124453</td>\n",
       "<td>0.9172846</td>\n",
       "<td>0.9202243</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1442827</td>\n",
       "<td>0.0056866</td>\n",
       "<td>0.1511335</td>\n",
       "<td>0.1433892</td>\n",
       "<td>0.1518792</td>\n",
       "<td>0.1517028</td>\n",
       "<td>0.1318069</td>\n",
       "<td>0.1399276</td>\n",
       "<td>0.1555891</td>\n",
       "<td>0.1467276</td>\n",
       "<td>0.1383138</td>\n",
       "<td>0.1323575</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>469.8</td>\n",
       "<td>19.156721</td>\n",
       "<td>480.0</td>\n",
       "<td>462.0</td>\n",
       "<td>493.0</td>\n",
       "<td>490.0</td>\n",
       "<td>426.0</td>\n",
       "<td>464.0</td>\n",
       "<td>515.0</td>\n",
       "<td>482.0</td>\n",
       "<td>461.0</td>\n",
       "<td>425.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6944455</td>\n",
       "<td>0.0116775</td>\n",
       "<td>0.6724684</td>\n",
       "<td>0.6969402</td>\n",
       "<td>0.6753277</td>\n",
       "<td>0.6890536</td>\n",
       "<td>0.6974323</td>\n",
       "<td>0.6997299</td>\n",
       "<td>0.6737811</td>\n",
       "<td>0.7000238</td>\n",
       "<td>0.7252263</td>\n",
       "<td>0.7144716</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7172135</td>\n",
       "<td>0.0074082</td>\n",
       "<td>0.7125748</td>\n",
       "<td>0.7130435</td>\n",
       "<td>0.7006679</td>\n",
       "<td>0.7206385</td>\n",
       "<td>0.7389706</td>\n",
       "<td>0.7107232</td>\n",
       "<td>0.7143649</td>\n",
       "<td>0.7096385</td>\n",
       "<td>0.7305669</td>\n",
       "<td>0.7209455</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7421954</td>\n",
       "<td>0.0144221</td>\n",
       "<td>0.7577687</td>\n",
       "<td>0.7299085</td>\n",
       "<td>0.7279838</td>\n",
       "<td>0.7552581</td>\n",
       "<td>0.7857701</td>\n",
       "<td>0.7220674</td>\n",
       "<td>0.7601511</td>\n",
       "<td>0.7195211</td>\n",
       "<td>0.7359868</td>\n",
       "<td>0.7275377</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>4.157928</td>\n",
       "<td>0.0945320</td>\n",
       "<td>4.2234044</td>\n",
       "<td>4.162791</td>\n",
       "<td>4.2046633</td>\n",
       "<td>3.9876542</td>\n",
       "<td>4.397279</td>\n",
       "<td>4.2458386</td>\n",
       "<td>4.081381</td>\n",
       "<td>4.0505548</td>\n",
       "<td>3.9443786</td>\n",
       "<td>4.2813334</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.3075063</td>\n",
       "<td>0.0129593</td>\n",
       "<td>0.3455034</td>\n",
       "<td>0.2983691</td>\n",
       "<td>0.3146811</td>\n",
       "<td>0.3021318</td>\n",
       "<td>0.2789586</td>\n",
       "<td>0.2910806</td>\n",
       "<td>0.3203061</td>\n",
       "<td>0.3101744</td>\n",
       "<td>0.3226586</td>\n",
       "<td>0.2911997</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2397286</td>\n",
       "<td>0.0222916</td>\n",
       "<td>0.2087766</td>\n",
       "<td>0.2583979</td>\n",
       "<td>0.2525907</td>\n",
       "<td>0.2197531</td>\n",
       "<td>0.1795918</td>\n",
       "<td>0.2701665</td>\n",
       "<td>0.2059186</td>\n",
       "<td>0.2737361</td>\n",
       "<td>0.2603550</td>\n",
       "<td>0.268</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.6233020</td>\n",
       "<td>0.0106780</td>\n",
       "<td>0.6170207</td>\n",
       "<td>0.6184740</td>\n",
       "<td>0.6015562</td>\n",
       "<td>0.6207566</td>\n",
       "<td>0.6577529</td>\n",
       "<td>0.6188925</td>\n",
       "<td>0.6147616</td>\n",
       "<td>0.6118274</td>\n",
       "<td>0.6376354</td>\n",
       "<td>0.6343433</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8231641</td>\n",
       "<td>0.0077941</td>\n",
       "<td>0.8289863</td>\n",
       "<td>0.817288</td>\n",
       "<td>0.8134783</td>\n",
       "<td>0.8256606</td>\n",
       "<td>0.8513334</td>\n",
       "<td>0.8150154</td>\n",
       "<td>0.8274128</td>\n",
       "<td>0.8105854</td>\n",
       "<td>0.8213900</td>\n",
       "<td>0.8204901</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1768360</td>\n",
       "<td>0.0077941</td>\n",
       "<td>0.1710137</td>\n",
       "<td>0.1827120</td>\n",
       "<td>0.1865217</td>\n",
       "<td>0.1743394</td>\n",
       "<td>0.1486666</td>\n",
       "<td>0.1849846</td>\n",
       "<td>0.1725872</td>\n",
       "<td>0.1894145</td>\n",
       "<td>0.17861</td>\n",
       "<td>0.1795100</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0944789</td>\n",
       "<td>0.0027157</td>\n",
       "<td>0.0975584</td>\n",
       "<td>0.0947295</td>\n",
       "<td>0.0972577</td>\n",
       "<td>0.0962749</td>\n",
       "<td>0.0846985</td>\n",
       "<td>0.0929907</td>\n",
       "<td>0.0953042</td>\n",
       "<td>0.0984002</td>\n",
       "<td>0.0962489</td>\n",
       "<td>0.0913261</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6803380</td>\n",
       "<td>0.0167339</td>\n",
       "<td>0.6481481</td>\n",
       "<td>0.6866029</td>\n",
       "<td>0.6594286</td>\n",
       "<td>0.6694915</td>\n",
       "<td>0.6722408</td>\n",
       "<td>0.6925881</td>\n",
       "<td>0.6491935</td>\n",
       "<td>0.6937574</td>\n",
       "<td>0.721709</td>\n",
       "<td>0.7102199</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.4830466</td>\n",
       "<td>0.0110002</td>\n",
       "<td>0.4601474</td>\n",
       "<td>0.4809804</td>\n",
       "<td>0.4634575</td>\n",
       "<td>0.4875900</td>\n",
       "<td>0.5179275</td>\n",
       "<td>0.4835364</td>\n",
       "<td>0.4847942</td>\n",
       "<td>0.4707678</td>\n",
       "<td>0.4914202</td>\n",
       "<td>0.4898443</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7602714</td>\n",
       "<td>0.0222916</td>\n",
       "<td>0.7912234</td>\n",
       "<td>0.7416021</td>\n",
       "<td>0.7474093</td>\n",
       "<td>0.7802469</td>\n",
       "<td>0.8204082</td>\n",
       "<td>0.7298335</td>\n",
       "<td>0.7940814</td>\n",
       "<td>0.7262639</td>\n",
       "<td>0.7396449</td>\n",
       "<td>0.732</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3073086</td>\n",
       "<td>0.0044893</td>\n",
       "<td>0.3123434</td>\n",
       "<td>0.3077815</td>\n",
       "<td>0.3118617</td>\n",
       "<td>0.3102819</td>\n",
       "<td>0.2910300</td>\n",
       "<td>0.3049438</td>\n",
       "<td>0.3087137</td>\n",
       "<td>0.3136881</td>\n",
       "<td>0.31024</td>\n",
       "<td>0.3022021</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8860567</td>\n",
       "<td>0.0110409</td>\n",
       "<td>0.8667492</td>\n",
       "<td>0.8929738</td>\n",
       "<td>0.8795473</td>\n",
       "<td>0.8710744</td>\n",
       "<td>0.8822587</td>\n",
       "<td>0.9001973</td>\n",
       "<td>0.8607443</td>\n",
       "<td>0.8949071</td>\n",
       "<td>0.9031351</td>\n",
       "<td>0.9089801</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "accuracy                 0.855717   0.00568664  0.848866      0.856611      0.848121      0.848297      0.868193      0.860072      0.844411      0.853272      0.861686      0.867642\n",
       "auc                      0.917203   0.0043945   0.906693      0.917767      0.911307      0.918391      0.931312      0.920037      0.916568      0.912445      0.917285      0.920224\n",
       "err                      0.144283   0.00568664  0.151134      0.143389      0.151879      0.151703      0.131807      0.139928      0.155589      0.146728      0.138314      0.132358\n",
       "err_count                469.8      19.1567     480           462           493           490           426           464           515           482           461           425\n",
       "f0point5                 0.694446   0.0116775   0.672468      0.69694       0.675328      0.689054      0.697432      0.69973       0.673781      0.700024      0.725226      0.714472\n",
       "f1                       0.717213   0.00740819  0.712575      0.713043      0.700668      0.720638      0.738971      0.710723      0.714365      0.709639      0.730567      0.720946\n",
       "f2                       0.742195   0.0144221   0.757769      0.729908      0.727984      0.755258      0.78577       0.722067      0.760151      0.719521      0.735987      0.727538\n",
       "lift_top_group           4.15793    0.094532    4.2234        4.16279       4.20466       3.98765       4.39728       4.24584       4.08138       4.05055       3.94438       4.28133\n",
       "logloss                  0.307506   0.0129593   0.345503      0.298369      0.314681      0.302132      0.278959      0.291081      0.320306      0.310174      0.322659      0.2912\n",
       "max_per_class_error      0.239729   0.0222916   0.208777      0.258398      0.252591      0.219753      0.179592      0.270166      0.205919      0.273736      0.260355      0.268\n",
       "mcc                      0.623302   0.010678    0.617021      0.618474      0.601556      0.620757      0.657753      0.618892      0.614762      0.611827      0.637635      0.634343\n",
       "mean_per_class_accuracy  0.823164   0.0077941   0.828986      0.817288      0.813478      0.825661      0.851333      0.815015      0.827413      0.810585      0.82139       0.82049\n",
       "mean_per_class_error     0.176836   0.0077941   0.171014      0.182712      0.186522      0.174339      0.148667      0.184985      0.172587      0.189415      0.17861       0.17951\n",
       "mse                      0.0944789  0.00271565  0.0975584     0.0947295     0.0972577     0.0962749     0.0846985     0.0929907     0.0953042     0.0984002     0.0962489     0.0913261\n",
       "precision                0.680338   0.0167339   0.648148      0.686603      0.659429      0.669492      0.672241      0.692588      0.649193      0.693757      0.721709      0.71022\n",
       "r2                       0.483047   0.0110002   0.460147      0.48098       0.463458      0.48759       0.517927      0.483536      0.484794      0.470768      0.49142       0.489844\n",
       "recall                   0.760271   0.0222916   0.791223      0.741602      0.747409      0.780247      0.820408      0.729834      0.794081      0.726264      0.739645      0.732\n",
       "rmse                     0.307309   0.00448927  0.312343      0.307782      0.311862      0.310282      0.29103       0.304944      0.308714      0.313688      0.31024       0.302202\n",
       "specificity              0.886057   0.0110409   0.866749      0.892974      0.879547      0.871074      0.882259      0.900197      0.860744      0.894907      0.903135      0.90898"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.156 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.201 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3796713</td>\n",
       "<td>3.4188301</td>\n",
       "<td>0.8155289</td>\n",
       "<td>2.8350811</td>\n",
       "<td>0.1873739</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.242 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3764685</td>\n",
       "<td>3.0939931</td>\n",
       "<td>0.8164008</td>\n",
       "<td>2.9296968</td>\n",
       "<td>0.1881883</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.283 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.3667262</td>\n",
       "<td>2.5705995</td>\n",
       "<td>0.8335322</td>\n",
       "<td>3.0308145</td>\n",
       "<td>0.1816686</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:46</td>\n",
       "<td>53.328 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.3591954</td>\n",
       "<td>2.1754763</td>\n",
       "<td>0.8448378</td>\n",
       "<td>3.1497184</td>\n",
       "<td>0.1785335</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:49</td>\n",
       "<td>56.925 sec</td>\n",
       "<td>66.0</td>\n",
       "<td>0.3105401</td>\n",
       "<td>0.3348466</td>\n",
       "<td>0.9131652</td>\n",
       "<td>4.1441670</td>\n",
       "<td>0.1490126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:49</td>\n",
       "<td>56.988 sec</td>\n",
       "<td>67.0</td>\n",
       "<td>0.3105157</td>\n",
       "<td>0.3348186</td>\n",
       "<td>0.9131317</td>\n",
       "<td>4.1440436</td>\n",
       "<td>0.1485519</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:50</td>\n",
       "<td>57.051 sec</td>\n",
       "<td>68.0</td>\n",
       "<td>0.3104649</td>\n",
       "<td>0.3347822</td>\n",
       "<td>0.9131897</td>\n",
       "<td>4.1438982</td>\n",
       "<td>0.1475999</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:50</td>\n",
       "<td>57.107 sec</td>\n",
       "<td>69.0</td>\n",
       "<td>0.3103963</td>\n",
       "<td>0.3337514</td>\n",
       "<td>0.9132453</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1409969</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-05-10 14:34:51</td>\n",
       "<td>58.301 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.3088862</td>\n",
       "<td>0.3173281</td>\n",
       "<td>0.9152451</td>\n",
       "<td>4.1526591</td>\n",
       "<td>0.1452965</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "     2018-05-10 14:34:46  53.156 sec  0.0                nan              nan                 nan             nan              nan\n",
       "     2018-05-10 14:34:46  53.201 sec  1.0                0.379671278305   3.4188300603        0.815528878936  2.83508106742    0.187373907196\n",
       "     2018-05-10 14:34:46  53.242 sec  2.0                0.376468519133   3.09399309253       0.816400815685  2.92969676599    0.188188290734\n",
       "     2018-05-10 14:34:46  53.283 sec  3.0                0.36672621347    2.57059945443       0.833532213426  3.03081449927    0.181668586474\n",
       "     2018-05-10 14:34:46  53.328 sec  4.0                0.359195390388   2.17547627621       0.844837764203  3.14971844877    0.178533513929\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---\n",
       "     2018-05-10 14:34:49  56.925 sec  66.0               0.310540061274   0.334846625121      0.913165213431  4.14416695421    0.149012622462\n",
       "     2018-05-10 14:34:49  56.988 sec  67.0               0.310515660391   0.334818590005      0.913131699444  4.14404362429    0.14855194865\n",
       "     2018-05-10 14:34:50  57.051 sec  68.0               0.310464949836   0.334782236896      0.913189698865  4.14389821543    0.147599889438\n",
       "     2018-05-10 14:34:50  57.107 sec  69.0               0.31039634959    0.333751370877      0.913245265737  4.1526590996     0.14099689813\n",
       "     2018-05-10 14:34:51  58.301 sec  100.0              0.308886169724   0.317328124574      0.915245087539  4.1526590996     0.145296520377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C8</td>\n",
       "<td>52661.3164062</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1695343</td></tr>\n",
       "<tr><td>C11</td>\n",
       "<td>42302.8593750</td>\n",
       "<td>0.8033005</td>\n",
       "<td>0.1361869</td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>36100.9257812</td>\n",
       "<td>0.6855303</td>\n",
       "<td>0.1162209</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>28606.3183594</td>\n",
       "<td>0.5432131</td>\n",
       "<td>0.0920932</td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>27755.6152344</td>\n",
       "<td>0.5270589</td>\n",
       "<td>0.0893545</td></tr>\n",
       "<tr><td>C5</td>\n",
       "<td>25600.5605469</td>\n",
       "<td>0.4861360</td>\n",
       "<td>0.0824167</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>23276.8378906</td>\n",
       "<td>0.4420102</td>\n",
       "<td>0.0749359</td></tr>\n",
       "<tr><td>C13</td>\n",
       "<td>18809.4824219</td>\n",
       "<td>0.3571784</td>\n",
       "<td>0.0605540</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>17458.1601562</td>\n",
       "<td>0.3315177</td>\n",
       "<td>0.0562036</td></tr>\n",
       "<tr><td>C12</td>\n",
       "<td>11310.0722656</td>\n",
       "<td>0.2147700</td>\n",
       "<td>0.0364109</td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>10894.1757812</td>\n",
       "<td>0.2068725</td>\n",
       "<td>0.0350720</td></tr>\n",
       "<tr><td>C14</td>\n",
       "<td>8426.4023438</td>\n",
       "<td>0.1600112</td>\n",
       "<td>0.0271274</td></tr>\n",
       "<tr><td>C9</td>\n",
       "<td>3719.1481934</td>\n",
       "<td>0.0706239</td>\n",
       "<td>0.0119732</td></tr>\n",
       "<tr><td>C10</td>\n",
       "<td>3701.5864258</td>\n",
       "<td>0.0702904</td>\n",
       "<td>0.0119166</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "C8          52661.3                1                    0.169534\n",
       "C11         42302.9                0.8033               0.136187\n",
       "C6          36100.9                0.68553              0.116221\n",
       "C1          28606.3                0.543213             0.0920932\n",
       "C7          27755.6                0.527059             0.0893545\n",
       "C5          25600.6                0.486136             0.0824167\n",
       "C4          23276.8                0.44201              0.0749359\n",
       "C13         18809.5                0.357178             0.060554\n",
       "C3          17458.2                0.331518             0.0562036\n",
       "C12         11310.1                0.21477              0.0364109\n",
       "C2          10894.2                0.206872             0.035072\n",
       "C14         8426.4                 0.160011             0.0271274\n",
       "C9          3719.15                0.0706239            0.0119732\n",
       "C10         3701.59                0.0702904            0.0119166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method ?.confusion_matrix of >\n"
     ]
    }
   ],
   "source": [
    "#Mostrando la matrix de consusion para estimar la precision out-of-bag y por validacion crizada\n",
    "print model.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHHCAYAAACcHAM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XtcVVX+//HXAQQxbiIgmpKMdyovoaZ4JQIRK5mmLEcp\nszQnasZynLJJRY00tcs0KWY1TPNtdBwpyrxgGunYaGqZYgYmCpoiGaJCoMhl//7wxxmPHIRDIOJ5\nPx8PHo/OPmuvvfZhHsPHtdd6H5NhGAYiIiIi1zCHxh6AiIiISE1UsIiIiMg1TwWLiIiIXPNUsIiI\niMg1TwWLiIiIXPNUsIiIiMg1TwWLiIiIXPNUsIiIiMg1TwWLiIiIXPNUsIg0YWVlZZhMJl588UWb\nz33nnXcwmUzs2bOnxraDBg3izjvvrMsQRUTqhQoWkXpy991306JFCwoLC6ttM3bsWJydnTl16tRV\nHNm1Z9y4cXh5eTX2MOrs559/Ji4ujv/85z+NPRQRu6GCRaSejBs3jnPnzpGcnGz1/eLiYj7++GMi\nIyNp1apVvVzTycmJc+fOMX369HrpT2rn559/Zvbs2SpYRK4iFSwi9eSee+7B3d2d5cuXW33/448/\npqioiLFjx/7ia1VUVHD+/HkAmjdvjqOj4y/uU2p26ecuIleXChaReuLq6sq9997Lpk2bOHnyZJX3\nly9fjpubG/fcc4/52Msvv0xISAje3t64urrSp0+fKjM0letUpkyZwj/+8Q+CgoJwcXFh06ZNVtew\nZGVl8bvf/Y4uXbrg6upKq1ateOCBBzhy5IjVcRcVFTFx4kS8vb3x9PRk/PjxnDlzpsb7PX/+PDNn\nzqRjx464uLgQEBDAc889x4ULF2r7kVlo164d0dHRfPbZZwQHB+Pq6krPnj3ZunUrAKtWreKWW26h\nefPm9OnTh71791qcX/mYKTMzk/DwcG644QZuvPFGXnzxRS7/UvrCwkKefvpp2rVrh4uLC926deO1\n116zaFfd5/7OO+/Qpk0bAGbMmIHJZLL4HezZs4eHHnqIwMBAmjdvjr+/P4899hj5+fkWY3jhhRcw\nmUxkZWXx0EMP4enpiZeXF4899hjnzp2r8vn84x//oG/fvrRo0QJvb2+GDh3Kpk2bLNqsXbuWQYMG\nccMNN+Dh4cHdd99Nenp6nX4fItcap8YegMj1ZOzYsbz33nv8+9//5sknnzQfz8/PZ8OGDYwZMwZX\nV1fz8b/85S/ce++9jB07lgsXLrB8+XLuvfde1q9fT2RkpEXfGzdu5F//+hexsbF4e3sTEBBgdQw7\nduxgx44d/Pa3v+XGG28kKyuLJUuW8NVXX/Htt99aXB/gd7/7Hd7e3syePZuMjAwSEhL44Ycf2LRp\nEyaTyeo1KioquOuuu/jyyy95/PHH6dq1K3v37uWVV14hMzOTpKSkOn1+Bw4cICYmhsmTJxMTE8OC\nBQu46667WLx4MS+88AK/+93vMAyDefPm8cADD5Cenm4xxtLSUiIjIxk0aBALFixg3bp1zJgxg4qK\nCmbOnGkx9q1bt/LYY4/Rs2dP1q9fzzPPPENOTg4LFy684uc+ePBg3nzzTZ588knuu+8+Ro0aBUCv\nXr0A2LBhA0eOHGHChAn4+/vz7bffsmzZMr777ju2bdtW5Z5/85vf0LFjR+bPn89XX33Fu+++S+vW\nrYmPjze3mTFjBi+++CKDBg1izpw5NGvWjB07dvD555+bF0P//e9/Z8KECYwYMYKXX36ZoqIilixZ\nwqBBg/jmm2+q/d+LSJNhiEi9KSsrM9q0aWMMGDDA4vjSpUsNwNiwYYPF8eLiYovXJSUlRvfu3Y2I\niAjzsdLSUgMwHB0djYyMDIv2le/NnTu32j4NwzC2bt1qAMby5cvNx95++20DMPr162eUlpaaj7/0\n0ksGYKxdu9Z8bODAgUZYWJj5dWJiouHg4GBs27bN4jpvvvmmARg7duyo+uFcYuzYsYanp6fFsRtv\nvLHKuWvXrjUAo0WLFsYPP/xgPr548WIDMLZu3WrRJ2A8/fTT5mMVFRXG8OHDDRcXF+PUqVOGYRhG\nUlKSARjz58+3aPfrX//acHBwMLKysgzDuPLnfuLEiSqfeyVrn////d//GYDF5/XnP//ZAIxJkyZZ\ntL377ruN1q1bm19nZGQYJpPJuO+++4zy8nKLthUVFYZhGMbZs2cNDw8P43e/+53F+zk5OVaPizRF\neiQkUo8cHR158MEH2b59O1lZWebjy5cvp3Xr1oSFhVm0r5ztMAyD06dPU1BQwKBBg9i9e3eVvu+4\n4w66du1a4xgunUG5cOECp06dolu3bri7u1vt9/HHH8fJ6X+TrbGxsTg4OLBu3bpqr7Fq1SpuvfVW\nOnfuTF5envnnjjvuAODzzz+vcZzW9OjRg379+plf33777QCEh4fTrl27KscPHz5cpY9LZ7ZMJhNP\nPvkkJSUlpKamArBu3TqaNWtWpd0zzzxDRUUFKSkpFv3V9nOvdOnnf/78efLy8ujfvz+A1c9/8uTJ\nFq8HDx7Mjz/+SHFxMQDJyckYhsGsWbNwcLD8v+zK2aUNGzZQUFDAmDFjLH4fzZo1o2/fvnX+fYhc\nS1SwiNSzykW1K1asAODYsWNs3bqVBx98sMri2NWrV3P77bfj6uqKt7c3vr6+vP3225w9e7ZKv4GB\ngbW6fnFxMS+88ALt2rWjefPm+Pj44OvrS2FhodV+O3fubPHaw8OD1q1bV7vmBeDgwYPs3bsXX19f\ni5+goCAAq2t4auPyxxaenp4AtG/f3urx06dPWxx3cnKiQ4cOFse6dOkCYL6fI0eO0K5dO2644QaL\ndt27d7doV6m2n3ulvLw8nnrqKfz8/HB1dcXX19f8GVv7/C+/55YtWwL/u7dDhw7h6OhIt27dqr3m\nwYMHARgyZEiV38lnn31W59+HyLVEa1hE6llwcDDdunVj+fLlPP/886xYsQLDMKrsDvr888+Jjo5m\n2LBhJCQk4O/vT7NmzXjnnXesrgG5fO1JdZ544gnef/99pkyZwoABA/Dw8MBkMnH//fdTUVFRqz6M\nyxapXq6iooJevXpVWe9Rqa7rJarb7VTd8ZrGaa1Nbc65VG0/90r33Xcfu3bt4k9/+hM9e/bkhhtu\noLS0lJEjR1r9/Gu6N8Mwql1LVKmy3+XLl+Pr61vl/WbNmtl0DyLXIhUsIg1g7NixzJgxg7S0NJYv\nX07nzp3p27evRZsPPviAFi1akJKSgrOzs/n422+//YuunZSUxIQJE1i0aJH5WHFxsdV/3cPFf50P\nHjzY/LqgoICTJ09y0003VXuNjh07kpGRcc2l35aVlZGdnc2vfvUr87HK2YfK++nQoQNbt26lqKjI\nYpYlIyPDot2VVFdA5OXlsWXLFuLj43n++efNx3/JTp1OnTpRVlZGRkYGt9xyi9U2HTt2BKB169bm\nx3Ii1xs9EhJpAJWzKTNnzmTPnj1Ws1ccHR1xcHCw+Ff34cOHWb169S+6tqOjY5VZhL/85S/Vziy8\n9dZblJWVmV8vXryYiooKRowYUe01Ro8ezdGjR/nb3/5W5b3i4mLz+ovG8Oabb5r/2zAMFi9ejIuL\ni/kPeVRUFKWlpSxZssTivNdeew0HB4cr3nelykLn8u3flbMll3/Wr7/+uu038v/9+te/xmQyMXv2\n7CozNJXXGTFiBO7u7sTHx1v8Liv99NNPdb6+yLVCMywiDSAwMJCQkBA+/vhjAKsFy1133cUbb7xB\nZGQkY8aMITc3l8WLF9OlSxf2799f52vfdddd/P3vf8fd3Z2uXbuybds2Nm/ebF4bcblz585x5513\nct9995Gens7SpUsZOnQoUVFR1V5j/PjxrFq1iscee4xNmzYREhJingX497//TWpqqnmb79XUokUL\nPv74Y/Lz8+nbty/r1q0jJSWFmTNn4u3tDVwsAIYMGcKzzz7LoUOH6NGjBykpKXzyySf88Y9/rNUM\ni5ubG126dGHFihV07NiRli1b0qNHD4KCgggJCWHevHmcP3+etm3bkpKScsX1QDXp2rUrzz33HPPm\nzWPo0KFER0fj7OzMrl27CAgI4MUXX8TLy4s333yTRx55hNtuu40HH3wQHx8fjhw5wtq1axk2bNgv\nKppErgmNsTVJxB5Ubr3t169ftW2WLVtmdOrUyXBxcTG6d+9uvPfee8af//xnw9HR0dymcnvtH/7w\nhyrnW9vWnJ+fbzz88MOGj4+P4ebmZowYMcL4/vvvjRtvvNF49NFHze0qtzVv3brVeOyxxwwvLy/D\n3d3diImJMfLz8y2uc/m2ZsMwjAsXLhjz5s0zgoKCDGdnZ6Nly5ZGnz59jDlz5hgFBQVX/Gyq29Y8\natQoq/d3+b0fPHjQAIzXXnutSp8HDx407rzzTsPV1dVo06aNMXv2bPP230oFBQXGH/7wB6NNmzZG\ns2bNjM6dOxuvvPKKRbsrfe6GcXGr+G233WY4Oztb/A6OHj1qREdHG56enoaXl5fxwAMPGMeOHavy\ne6rc1nz69GmLfit/L5du4zYMw3jnnXeMXr16GS4uLkbLli2NYcOGGZ999plFm88++8wIDw83PDw8\nDFdXV6NTp07GI488Ynz99ddW70GkKTEZho0r0ERErkHjxo1jzZo1tUrpFZGmR2tYRERE5JqngkVE\nRESueSpYRERE5JqnNSwiIiJyzdMMi4iIiFzzVLCIiIjINa/JBsdVVFSQk5ODu7t7jd+zISIiItcG\nwzAoLCykbdu2Vb6B/EqabMGSk5NT5RtcRUREpGn44YcfaNeuXa3bN9mCxd3dHbh4wx4eHo08GhER\nEamNgoIC2rdvb/47XltNtmCpfAzk4eGhgkVERKSJsXU5hxbdioiIyDVPBYuIiIhc81SwiIiIyDVP\nBYuIiIhc81SwiIiIyDVPBYuIiIhc81SwiIiIyDVPBYuIiIhc81SwiIiIyDVPBYuIiIhc81SwiIiI\nyDVPBYuIiIhc81SwiIiIyDWvTgVLbm4uTz31FL/61a9wcXGhffv23H333Xz22WcALFu2jGHDhuHh\n4YHJZOLMmTNV+vj+++8ZNWoUPj4+eHh4MGjQIDZv3vyLbkZERESuT062npCdnc3AgQPx8vJiwYIF\n9OjRg9LSUjZs2EBsbCwZGRkUFxcTGRlJZGQk06dPt9rPXXfdRefOnUlNTcXV1ZXXX3+dkSNHcujQ\nIfz9/Ws9Hs95ntDc1rsQERGRKzFmGY09BAsmwzBsGlFUVBRpaWkcOHCAG264weK9M2fO4OXlZX69\nefNmQkNDOX36tMXxvLw8fH19+c9//sPgwYMBKCwsxMPDg40bN3LnnXfWOI6CggI8PT3hOVSwiIiI\n1LOGKlgq/36fPXsWDw+PWp9n0yOh/Px8UlJSiI2NrVKsABZFyZW0atWKrl278o9//IOioiLKysp4\n66238PPzIzg42JYhiYiIiB2w6ZFQZmYmhmHQrVu3X3RRk8nEpk2biI6Oxt3dHQcHB/z8/EhJSaFl\ny5ZWzykpKaGkpMT8uqCg4BeNQURERJoOm2ZYKp8emUymX3RRwzCIjY3Fz8+PrVu3snPnTqKjo7n7\n7rs5ceKE1XPmzZuHp6en+ad9+/a/aAwiIiLSdNhUsHTu3BmTyUR6evovumhqaipr1qzhX//6FwMH\nDuS2225jyZIluLq68t5771k9Z/r06Zw9e9b888MPP/yiMYiIiEjTYVPB4u3tzfDhw1m8eDFFRUVV\n3re2fdma4uLiixd3sLy8g4MDFRUVVs9xcXHBw8PD4kdERETsg83bmpcsWUJISAj9+vVjzpw59OjR\ng7KyMjZu3EhCQgLp6enk5uaSm5tLZmYmAPv27cPd3Z2AgAC8vb0ZMGAALVu25OGHH2bmzJm4urry\n9ttvk5WVxciRI20az9nptq0yFhERkabH5uC4wMBAdu/eTWhoKFOnTuWWW24hPDyczz77jISEBACW\nLl1K7969mThxIgBDhgyhd+/erF69GgAfHx9SUlL4+eefueOOO+jTpw9ffPEFH3/8MT179qzH2xMR\nEZHrgc0zLHBx0a3JZDI/0jGZTFRUVFBeXk5+fj6nTp2iS5cu/PDDD/j4+BAdHc3cuXMv5qb8f//3\nf/9HXl4eP//8M927d2f79u11ugEFx4mISGO41oLVrnf1nnSblJRETk4OixYtIigoiCNHjjB58mRy\ncnJISkoy92MYBhMmTGDHjh2kpaXV602JiIjI9aVBk24rrVq1inHjxlFUVISTk2WNFBcXx0cffcSe\nPXtsGriSbkVEpDFphqVu6pp0a9MMS2XSbXx8vE1Jt5WDurxYsYWC40REROyXTYtu65J0m5eXx9y5\nc5k0aZLNg7uUguNERETsV4Mm3RYUFDBy5EiCgoKIi4uzeXCXUnCciIiI/WqwpNvCwkIiIyNxd3cn\nOTmZZs2a1XmQoOA4ERERe9YgSbcFBQVERETg7OzM6tWrad5cq2JFRESk7uo96Xbnzp1ERERQXFzM\n+++/T0FBgXmBrK+vL46OjsDF9TA///wzubm5nDt3zrxLKCgoCGdn51qPR0m3IiIi1z+btzUD7N27\nl5iYGNLT0ykrK8PR0REfHx+mTZtGcHAwoaGhVs/LysqiQ4cOAAwbNowtW7Zcsc2V1HVblIiIiDSe\nq7KtGS4Gx0VFReHl5cWKFSssguOWLVvG1KlTee211zh//jxwcbHs6dOnq2x5fuqpp0hLS+Oll17i\njjvuoKysjG+//bZWxcqllHQrIiJXmzJYrr4GDY7bvHkzoaGhVQqWsrIyOnTowOzZs3n00UfrNHAF\nx4mISGNRwVJ3dZ1hsWnRbWVwXGxsrE3BcZfbvXs3x48fx8HBgd69e9OmTRtGjBjB/v37qz2npKTE\nvB7m0nUxIiIicv1r8OA4aw4fPgxcjOV/4YUXWLNmDS1btmTo0KHk5+dbPUfBcSIiIvarQYPjqlNR\nUQHAn//8Z37zm98QHBxMYmIiJpOJVatWWT1HwXEiIiL2q8GC466kTZs2wMUtzJVcXFz41a9+xdGj\nR62eo+A4ERER+9UgwXE1CQ4OxsXFhQMHDpiPlZaWkp2dzU033WTLkERERMQO1HtwXHp6Orm5ueTm\n5pKZmQnAvn37cHd3JyAgAG9vbzw8PJg8eTKzZs2iffv23HTTTSxcuBCA+++/36bxKDhORETk+mdz\nwRIYGMju3buJj49n6tSpnDhxAl9fX4KDg0lISABg6dKlzJ4923zOkCFDAEhMTGT8+PEALFy4ECcn\nJ2JiYjh37hy33347qamptGzZsh5uS0RERK4nNhcscHHRrclkwsHBwfy6oqKC8vJyANq2bcvQoUPZ\nvXs3hYWFVXJYKvNZLrVp0yZuueUWdu7cSd++fWs9FgXHiYhIJeWjXL/qlHQ7cOBAvLy8WLBggUXS\nbWxsLBkZGRQXFxMZGUlkZCTTp0+v0kdISAgnTpywODZjxgw2bdpEnz596n43IiIicl2yuWB54okn\nMJlM7Ny50yI87uabb2bChAkATJkyBbg4k2KNs7Mz/v7+5telpaWsXr2aJ5988hdvmRYREZHrj00F\nS2XSbXx8/C9Kur3c6tWrycvLM69vsaakpISSkhLzayXdioiI2I9GSbq93Lvvvsvw4cOvmF6rpFsR\nERH71ShJt5c6duwYGzZsqPFLEJV0KyIiYr8aJen2UomJibRq1Yp77rnniu2UdCsiImK/GiXptpJh\nGCQmJvLQQw/RrFkzm84VERER+9EoSbeVUlNTycrKqvFx0JUo6VZEROT6ZzIqF6bYYO/evcTExJCe\nnk5ZWRmOjo74+Pgwbdo0HnnkESIjI9m1a1eV8y5Nuj169CgDBgwgNzeXVq1a8fDDDzNv3jycnGpX\nQxUUFODp6QnPoeA4EZEmToFv9qPy7/fZs7ZNONQpOC4qKgovLy9WrFhhERy3bNky826fGTNmEBQU\nxJEjR5g8eTI9evQwFyvl5eWMHDmSoKAg1q5dy4kTJ8yPhV566SVbhyQiIiLXOZtnWKKiokhLS+PA\ngQNVsljOnDljNYtl1apVjBs3jqKiIpycnFi/fj133XUXOTk5tG7dGrj4/UPPPvssP/30E87OzjWO\nQzMsIiLXD82w2I+6zrDYtOi2MjguNjbWpuC4ykFVPu7Zvn07t956q7lYARg+fDgFBQXs37/fah8l\nJSUUFBRY/IiIiIh9aPDguLy8PObOncukSZPMx3Jzcy2KFcD8Ojc312o/Co4TERGxXw0aHFdQUGBe\nqxIXF1erc6rrW8FxIiIi9qvBguMKCwuJjIzE3d2d5ORki5wVf39/fvzxR4v2la8vn3mppOA4ERER\n+9UgwXEFBQVERETg7OzM6tWrad7cclXsgAED2LdvHydPnjQf27hxIx4eHgQFBdXlPkREROQ6ZvMu\noaysLEJCQvD29rYaHLdz507Cw8MpLi4mOTnZYnGur68vjo6OlJeX06tXL9q2bcuCBQvIzc0lJiaG\nxx57rNbbmuu6ylhEREQaT13/ftd7cFxwcDChoaFWz8vKyqJDhw4AhIeH88UXX3D+/HlMJhPdunUj\nJSWFgICAWo1BBYuIiEjTc9UKluzsbAYOHIiXlxezZ8+uEhyXkZHB66+/zvnz54GLi2VPnz5dZcvz\na6+9xoABA2jTpg3Hjx/nj3/8IwDbtm2r1TiUwyIicvUoJ0Xqy1UrWGwJjtu8eTOhoaFWC5bLrV69\nmujoaEpKSmr1RYgqWERErh4VLFJfrunguNr0+89//pOQkBB9a7OIiIhU0eDBcVfy7LPPcsMNN9Cq\nVSuOHj3Kxx9/XG1bJd2KiIjYrwYNjqvJtGnT+Oabb/j0009xdHTkoYceoronVEq6FRERsV8NFhxX\nGz4+PnTp0oXw8HD+9a9/sW7dOr788kurbZV0KyIiYr8aJDiuLioqKoCLj36sUdKtiIiI/XKy9YQl\nS5YQEhJCv379rAbHpaenk5ubS25uLpmZmQDs27cPd3d3AgIC8Pb2ZufOnezcuZNBgwbRsmVLDh06\nxIwZM+jYsSMDBgywaTxnpyuHRURE5Hpn0wwLQGBgILt37yY0NJSpU6dyyy23EB4ezmeffUZCQgIA\nS5cupXfv3kycOBGAIUOG0Lt3b1avXg2Aq6srH374IWFhYXTt2pVHH32UHj16sGXLFlxcXOrx9kRE\nROR6YPMMC1xcdGsymXBwcDC/rqiooLy8HIC2bdsydOhQdu/eTWFhYZUclltvvZXU1FTg4iOg22+/\nnaVLl/L4449z44032jQWz3meymEREalnyl2Ra43NMyzZ2dkEBweTmprKggUL2LdvHykpKYSGhhIb\nGwtAcXExkZGRPP/88zX296c//Ym2bdvaPnIRERGxGzbPsDzxxBOYTCZ27txpER538803M2HCBACm\nTJkCXEy6vZL169fz6aef8sEHH7B+/XpbhyIiIiJ2wqaCpTLpNj4+/hcn3f74449MnDiRjz76iBYt\nWtTYvqSkxGIHkYLjRERE7EejJN0ahsH48eOZPHkyffr0qdU5Co4TERGxX42SdPvXv/6VgoICpk+f\nXutzFBwnIiJivxol6TY1NZUvv/wSFxcXnJyc6NSpEwB9+vTh4YcftnqOguNERETsV6Mk3b7xxhvs\n3buXPXv2sGfPHtatWwfAypUriY+Pt2VIIiIiYgcaJek2ICDAok83NzcAOnbsSLt27Wwaj5JuRURE\nrn82FyyBgYGkpKQQExPDgw8+SFlZGY6Ojvj4+DBt2jTy8/O555572LVrl/mcIUOGAJCYmMj48eMt\n+jt16pQ5jr+wsPAX3IqIiIhcr2wuWLKzs4mKisLLy4sVK1bQo0cPSktL2bBhA8uWLWP48OG0b9+e\nGTNmEBQUxJEjR5g8eTI9evSoUqwAPProo/Tu3Zv169dz66232nwDSroVEbGdkmylqTEZlVt/aikq\nKoq0tDQOHDhQJYvlzJkzVrNYVq1axbhx4ygqKsLJ6X81UkJCAitXrmTmzJmEhYVVifC/koKCAjw9\nPeE5VLCIiNhIBYs0lsq/32fP2rak46oEx1UO6tJi5bvvvmPOnDns2LGDw4cP13htBceJiIjYrwYP\njsvLy2Pu3LlMmjTJfKykpIQxY8awcOHCKgtwq6PgOBEREfvVoMFxBQUFjBw5kqCgIOLi4szHp0+f\nTvfu3Rk3blytr63gOBEREfvVYMFxhYWFREZG4u7uTnJyMs2aNTO/l5qayqpVq3BycsLJyYmwsDAA\nfHx8mDVrltX+FBwnIiJiv2xedDtixAj27dt3xUW3BQUFDB8+HBcXF9atW1flyw0PHTrEuXPnzK93\n7drFhAkT2LZtGx07dsTPz6/GcWjRrYhI3WnRrTSWui66tblgycrKIiQkBG9vb6vBcTt37iQ8PJzi\n4mKSk5MtihpfX18cHR2r9Ll582ZCQ0PrtEvI1hsWERGRxnNVdglBzcFxn3/+OTt27AAwf0dQpays\nLDp06MDevXuZP38+X3zxBXl5ebWaURERERH7Ve/BcUlJSdx7772MHz++SnBchw4dAPj666/x9fXl\n/fffp3379mzbto1Jkybx/vvv8+STT9o0HgXHiYjUTI+ApKlr1OC4S8XGxpKenk5qamqtxqE1LCIi\ntaeCRa4VdX0kZNMuocrguNjY2F8cHGetjbe3ty3DERERETth0yOh+gqOu9y2bdtYuXIla9eurbaN\nkm5FRETsV6MEx13q22+/ZdSoUcyaNYuIiIhq+1LSrYiIiP1qlOC4St999x1hYWFMmjSJF1544Yr9\nKelWRETEftlUsHh7ezN8+HAWL15MUVFRlffPnDkDXJxZiYiIwNnZmdWrV9O8edVVsfv37yc0NJSH\nH36Y+Pj4Gq+tpFsRERH7ZVPBArBkyRLKy8vp168fH3zwAQcPHiQ9PZ033niDAQMGUFhYSEREBEVF\nRbz77rsUFBSQm5tLbm4u5eXlwP+KlfDwcJ555hnz+z/99FO936CIiIg0fTZvawY4ceIE8fHxrFmz\nhhMnTuDr60twcDBPP/00AKGhoVbPqwyOi4uLY/bs2VXev+mmm8jOzq7VGJR0KyIi0vRctaRbuLjo\n1mQy4eBIlODJAAAgAElEQVTgYH5dUVFBeXm5eU3Kpk2byMnJwc3NjZCQEF5++WVzcNxTTz3Fl19+\nSVpaGqdOncLPz49Ro0bx0ksv2TwWBceJSGNQronI1WXzI6Hs7GyCg4NJTU1lwYIF7Nu3j5SUFEJD\nQ4mNjQUgODiYxMRE0tPT2bBhA4ZhEBERYX4k5ODgwKhRo1i9ejXff/89f//739m0aROTJ0+u37sT\nERGR68JVSbpNS0ujZ8+eZGZm0rFjR6v9vvHGGyxcuLDWu3+UdCsijUkzLCJ1c1UeCVUm3cbHx9c6\n6baoqIjExEQCAwOrzU7Jycnhww8/ZOjQodVeW8FxIiIi9sumR0K2JN0uWbIENzc33NzcSElJYePG\njTg7O1u0GTNmDC1atODGG2/Ew8ODd955p9r+FBwnIiJivxos6Xbs2LF88803bNmyhc6dOzN69GjO\nnz9v0ea1115j9+7dfPTRRxw6dIhnnnmm2v4UHCciImK/bHokdGnSbXR09BXbVs6EdO7cmf79+9Oy\nZUuSk5MZM2aMuY2/vz/+/v5069aNVq1aMXjwYGbMmEGbNm2q9Ofi4oKLi4stwxUREZHrRIMk3V7O\nMAwMw7BYg3K5iooKgCu2EREREftk8y6hrKwsQkJC8Pb2Zs6cOfTo0YOysjI2btxIQkICa9euZeXK\nlURERODr68uxY8eYP38+//3vf0lPT8fPz49169bx448/0rdvX9zc3Ni/fz/Tpk3D29ubL774olbj\nUHCciIhI03PVguMCAwNJSUkhJiaGBx98kLKyMhwdHfHx8WHatGmcO3eOt956ixkzZlBeXo6joyMd\nO3Zkw4YN+Pn5AeDq6sqiRYs4cOCAuU2fPn346KOPbB2OiIiI2AGbC5bs7GyioqLw8vJixYoV9OjR\ng9LSUjZs2MCyZcsYPnw4wcHB/PWvfyUoKIgjR44wefJk5s+fT1JSEgCtWrUiMzOTmTNn8tvf/pbj\nx4+b2yxatMim8SjpVkSsUU6KyPXlqgTHrVq1inHjxlFUVISTkxPPP/88GzduZNeuXeY2n3zyCaNH\nj+bkyZO4u7vXOA4Fx4nIlahgEbk21fWRkE2LbiuD42JjY2sdHAeYB+XkdHFCp6SkhObNLasMV1dX\nzp8/z9dff23LkERERMQONFhwXKW8vDzmzp3LpEmTzMeGDx/Otm3bWLFiBeXl5Rw/fpw5c+YAF78J\n2pqSkhIKCgosfkRERMQ+NFhwHFyc9hk5ciRBQUHExcWZj0dERLBw4UImT56Mi4sLXbp0ISoqCgBH\nR0erfSnpVkRExH7ZVLBcGhxXk8LCQiIjI3F3dyc5OZlmzZpZvP/MM89w5swZjh49Sl5eHqNGjQIu\n7kKyRkm3IiIi9qtBguMKCgqIiIjA2dmZ1atXV1mvUslkMtG2bVtcXV1ZsWIF7du357bbbrPa1sXF\nBQ8PD4sfERERsQ/1Hhy3c+dOwsPDKS4uJjk52WJxrq+vr/mRz8KFC4mMjMTBwYEPP/yQuXPn8u9/\n/7vGyP9KCo4TERFpeur699vmggUuLoyNj49nzZo1nDhxAl9fX4KDg3n66acBCA0NtXpeVlYWHTp0\nAOCOO+5g9+7dlJSU0LNnT2bNmsWIESNqPQYVLCIiIk3PVUu6hYuPckwmEw4ODubXFRUVlJeXExYW\nxqRJk9i0aRM5OTm4ubkREhLCyy+/bC5WAFJTU/n73//Oq6++yp49e3j44Ye5//77Wbx4sU1jUXCc\nSNOhbBQRqas6Jd0OHDgQLy8vFixYYJF0GxsbS0ZGBsHBwYwdO5aAgADy8/OJi4sjIiKCrKws8yOh\nV199lVdeeYWFCxdy++23U1RURHZ2dn3fn4iIiFwHrkrSbVpaGj179iQzM5OOHTty+vRpbrzxRj75\n5BPCwsLqNHAl3Yo0PZphEZFrNum2qKiIxMREAgMDzdkpGzdupKKiguPHj9O9e3fatWvH6NGjr7hV\nWcFxIiIi9qvBkm6XLFmCm5sbbm5upKSksHHjRpydnQE4fPgwFRUVvPTSS7z++uskJSWRn59PeHg4\nFy5csNqfguNERETsV4Ml3Y4dO5ZvvvmGLVu20LlzZ0aPHs358+cBqKiooLS0lDfeeIPhw4fTv39/\nVqxYwcGDB/n888+t9qfgOBEREfvVYEm3np6edO7cmSFDhpCUlERGRgbJyckAtGnTBoCgoCBze19f\nX3x8fDh69KjV/hQcJyIiYr8aJOn2coZhYBgGJSUlAAwcOBCAAwcOmNvk5+eTl5fHTTfdZMuQRERE\nxA7Ue9Lt2rVrWblyJREREfj6+nLs2DHmz5/Pf//7X9LT0/Hz8wMgOjqazMxMli1bhoeHB9OnT+fw\n4cPs2bOnyvcOWaPgOBERkabnqibd7t27l5iYGNLT0ykrK8PR0REfHx+mTZvGmDFjiIiI4Pvvv6e0\ntBSA++67jxdffJGuXbua+8jOziYsLIzDhw9jMpkICAggJSWlVgt6QQWLiIhIU3TVCpZLg+Nmz55t\nERy3bNkyMjIyeP31180LbKdPn87p06erbHkeMWIEJ06c4K233qK0tJRHHnmEvn37snz58lqNQzks\nIg1DWSki0pCuWsFiS3Dc5s2bCQ0NrVKwpKenExQUxK5du+jTpw8AKSkpREVFcezYMdq2bVvjOFSw\niDQMFSwi0pCu2eA4a7Zv346Xl5e5WAG48847cXBwYMeOHVbPUXCciIiI/Wqw4Lgryc3NNS++reTk\n5IS3tze5ublWz1FwnIiIiP1qsOC4ujAMo9q+FRwnIiJivxosOO5K/P39OXnypMWxsrIyTp8+TevW\nra2eo+A4ERER+3VVguMuN2DAAM6cOcPXX39tPpaamkpFRQW33367LUMSERERO1DvwXHp6enk5uaS\nm5vLV199xcSJE/nPf/6Du7s7AQEBeHt7Axe3Nf/4448sXbrUvK25T58+Nm9rVg6LiIhI01HXv99O\ntl4oMDCQ3bt3Ex8fz9SpUzlx4gS+vr4EBweTkJAAwNKlS5k9e7b5nCFDhgDQs2dPXnnlFcLCwigs\nLOSbb76xmFEZPHiwrcMRERERO1CnpNua1CZcbtiwYXTp0oU5c+aYz2vRokWtqy3lsIj8j7JTRKSp\nuGozLLXxxBNPYDKZ2Llzp0Vey80338yECRPMr1u0aIG/v39DDEFERESuIzYtuq0NW8Ll/vnPf+Lj\n48Mtt9zC9OnTKS4uru/hiIiIyHWg3mdYahsu99vf/pabbrqJtm3bkpaWxrPPPsuBAwf48MMPrbYv\nKSmhpKTE/FpJtyIiIvaj3guW2obLTZo0yfzft956K23atCEsLIxDhw7RsWPHKu3nzZtnsZBXRERE\n7Ee9PxKqa7hc5W6hzMxMq+8r6VZERMR+1XvBUtdwuT179gDQpk0bq+8r6VZERMR+Nci25prC5das\nWcPy5cuJioqiVatWpKWl8fTTT9OuXTu2bNlSq2soOE5ERKTpuaa2NdcULufs7MymTZt4/fXXKSoq\non379vzmN7/hhRdeaIjhiIiISBPXIAULXFx0azKZcHBwML+uqKigvLyc9u3bs2XLFrZv386f//xn\nduzYwdKlS/nyyy/ZsGEDrq6utb6O5zxPBceJXVNonIjYgwYpWC5Nul2wYIFF0m1sbCwZGRls376d\nyMhIpk+fzl//+lecnJzYu3evucARERERqdQga1iioqJIS0vjwIEDVcLjzpw5g5eXF/379yc8PJy5\nc+fW6RqK5he5SDMsItKU1HUNS6Mk3Z48eZIdO3bg5+dHSEgIrVu3ZujQoXzxxRfV9ltSUkJBQYHF\nj4iIiNiHei9YapN0e/jwYQDi4uKYOHEiKSkp3HbbbYSFhXHw4EGr58ybNw9PT0/zT/v27et76CIi\nInKNqveCpTZJtxUVFQA8/vjjPPLII/Tu3ZvXXnuNrl278re//c3qOQqOExERsV+NknRbGQ4XFBRk\ncbx79+4cPXrU6jkKjhMREbFfjZJ026FDB9q2bcuBAwcs3vv++++56aab6ntIIiIi0sQ1yLbmJUuW\nEBISQr9+/awm3aanpzNt2jRmzZpFz5496dWrF++99x4ZGRkkJSXZdK2z05V0KyIicr2rU8GSm5tL\nfHw8a9eu5fjx4/j5+dGrVy+mTJlCWFgY8+fPx8XFhQMHDjB69GgMw8DX15f+/fuTkJAAwJQpUzh/\n/jy///3vyc3NxTAM1q1bZ/WbmkVERMS+2ZzDcmko3OzZsy1C4ZYtW0ZGRgbLli2jW7duBAQEkJ+f\nT1xcHHv27CErKwtHR0eL/qKjo7lw4QLr16/n9OnTeHl51WocymERe6f8FRFpiuqaw2JzwVKbULjL\npaWl0bNnTzIzMy1mUBISEli5ciUzZ84kLCxMBYuIDVSwiEhTdFW+/LAyFC4+Pr7aULjLFRUVkZiY\nSGBgoEV2ynfffcecOXPYsWOHOZflSkpKSigpKTG/VnCciIiI/bBpl1BtQuEqLVmyBDc3N9zc3EhJ\nSWHjxo04OzsDF4uPMWPGsHDhQgICAmp1bQXHiYiI2C+bCpbahMJVGjt2LN988w1btmyhc+fOjB49\nmvPnzwMXQ+C6d+/OuHHjan1tBceJiIjYL5sKltqEwlXy9PSkc+fODBkyhKSkJDIyMkhOTgYgNTWV\nVatW4eTkhJOTE2FhYQD4+Pgwa9Ysq/0pOE5ERMR+2bSG5dJQuN///ve1XnRrGAaGYZjXoHzwwQec\nO3fO/P6uXbuYMGECW7du1bZmERERqcLmHJaaQuHWrl3LypUriYiIwNfXl2PHjjF//nxcXV2JiooC\nqFKU5OXlARej+Wu7S6iSguNERESufzYXLIGBgezevZv4+HimTp3KiRMn8PX1JTg4mISEBJo3b87W\nrVt5/fXXOX36NK1bt2bIkCFs27YNPz+/hrgHERERuc7ZnMNSW1dKw+3duzezZs3i008/5YcffsDH\nx4fo6Gjmzp17MVulFpTDIvZMGSwi0lRdlRyW2ro0DXfBggUWabixsbEkJSWRk5PDokWLCAoK4siR\nI0yePJmcnBybv0tIRERErn8NMsNSlzTcVatWMW7cOIqKinByqrmO0gyL2DPNsIhIU3XNzLDUJQ0X\nMA+8umJFSbciIiL2y6YcltqwJQ23Ul5eHnPnzmXSpEnVtlHSrYiIiP2q94LFljRcuDhTMnLkSIKC\ngoiLi6u2nZJuRURE7Fe9Fyy2pOEWFhYSGRmJu7s7ycnJNGvWrNq2SroVERGxX/VesFyahltUVFTl\n/TNnzgAXZ1YiIiJwdnZm9erVNG+ulbMiIiJiXYPsEsrKyiIkJARvb2+rabg7d+4kPDyc4uJikpOT\nLRbn+vr64ujoWOM16rrKWERERBpPXf9+N1hw3N69e4mJiSE9PZ2ysjIcHR3x8fFh2rRpBAcHExoa\navW8rKwsOnToUGP/2tYsTZW2JIuIPatrwVLvj4TgYnBcVFQU5eXlrFixggMHDrB3717+9Kc/8fbb\nb9O3b19+9atf8etf/5q0tDTS0tIYNWoUffv2JSAgoCGGJCIiIk1YowTH7dy5kxEjRnD69GlzdXX2\n7FlatmzJp59+yp133lnjNTTDIk2VZlhExJ5dMzMslcFxsbGx1QbHlZSUYDKZcHFxMR9v3rw5Dg4O\nfPHFF1b7LSkpoaCgwOJHRERE7EOjBMf179+fG264gWeffZbi4mKKior44x//SHl5OSdOnLB6joLj\nRERE7FejBMf5+vqyatUqPvnkE9zc3PD09OTMmTPcdttt1e4QUnCciIiI/ar37xK6NDguOjq62nYR\nEREcOnSIvLw8nJyc8PLywt/fn8DAQKvtXVxcLB4hiYiIiP1otOC4Sj4+Pnh5eZGamsrJkye55557\n6ntIIiIi0sTV+wwLwJIlSwgJCaFfv35Wg+PS09NJTEyke/fu+Pr6sn37dv7whz/w9NNP07VrV5uu\ndXa6guNERESud3UqWHJzc4mPj2ft2rUcP34cPz8/evXqxZQpUwgLC2P+/Pm4uLhw4MABRo8ejWEY\n+Pr60r9/fxISEgDYtWsXkydP5sKFCzg6OjJ48GDmz59frzcnIiIi1webc1iys7MZOHAgXl5ezJ49\nmx49elBaWsqGDRtYtmwZGRkZLFu2jG7duhEQEEB+fj5xcXHs2bOHrKwsHB0dKS8vp1evXvj7+7Nw\n4UJOnDjBQw89xMSJE3nppZdqNQ7lsEhTodwVEZH/uWrR/DWFwnl5eVU5Jy0tjZ49e5KZmUnHjh1Z\nv349d911Fzk5ObRu3RqApUuX8uyzz/LTTz/h7Oxc4zhUsEhToYJFROR/rkpwXG1C4S5XVFREYmIi\ngYGB5uyU7du3c+utt5qLFYDhw4dTUFDA/v37bRmSiIiI2AGbCpbahMJVWrJkCW5ubri5uZGSksLG\njRvNMye5ubkWxQpgfp2bm2u1PyXdioiI2C+bCpbahMJVGjt2LN988w1btmyhc+fOjB49mvPnz9d4\nXnV9K+lWRETEftlUsFwaClcTT09POnfuzJAhQ0hKSiIjI4Pk5GQA/P39+fHHHy3aV76+fOalkpJu\nRURE7JdNBYutoXCVDMPAMAxKSkoAGDBgAPv27ePkyZPmNhs3bsTDw4OgoCCrfbi4uODh4WHxIyIi\nIvbB5l1CWVlZhISE4O3tbTUUbu3ataxcuZKIiAh8fX05duwY8+fP57///S/p6en4+fmZtzW3bduW\nBQsWkJubS0xMDI899pjN25ptXWUsIiIijeeq7BICCAwMZPfu3YSGhjJ16lRuueUWwsPD+eyzz0hI\nSKB58+Zs3bqVqKgoOnXqxAMPPIC7uzvbtm3Dz88PAEdHR9asWYOjoyMDBgxg3LhxPPTQQ8yZM8fW\n4YiIiIgdqFPSrclkwmQy4eDgYH5dUVFBeXk5zZs3p2PHjhw6dIjCwkJMJhOtWrXC39/foo8OHTqY\n//vcuXO88sor9OnThwcffNCmsXjO81QOizQq5ayIiDQ8mwuWS5NuFyxYYJF0GxsbS1JSEjk5OSxa\ntIigoCCOHDnC5MmTycnJISkpyaKvxMREIiMjza+t5biIiIiI2FywPPHEE5hMJnbu3GkRHnfzzTcz\nYcIEvLy8+OCDD8zHO3bsSHx8POPGjaOsrAwnp/9d0svLq8rMi4iIiMjlGjzpFjAvrLm0WAGIjY3F\nx8eHfv368be//Y0rrf9VcJyIiIj9smmGxZak20p5eXnMnTuXSZMmWRyfM2cOd9xxBy1atODTTz/l\niSee4Oeff+b3v/+91X7mzZvH7NmzbRmuiIiIXCds2ta8Y8cO+vfvT3JyMtHR0TW2LygoIDw8HG9v\nb1avXk2zZs2qbTtz5kwSExOrDYQrKSkx57hU9t2+fXt9+aE0Oi26FRGpvauyrdmWpNvCwkIiIyNx\nd3cnOTn5isUKwO23386xY8eqje9XcJyIiIj9apCk24KCAiIiInB2dmb16tU0b17zFMiePXto2bJl\nrdqKiIiIfbF5l9CSJUsICQmhX79+VpNud+7cSUREBMXFxbz//vsWC2R9fX1xdHTkk08+4eTJk/Tv\n3x8XFxc2btzISy+9xB//+Eebb+DsdCXdioiIXO9sLlgCAwNJSUkhJiaGBx98kLKyMhwdHfHx8WHa\ntGl8/vnn7NixA4BOnTpZnJuVlUWHDh1o1qwZCxYs4NChQ5SXl+Po6EjXrl1rtS5GRERE7E+dguOi\noqLw8vJixYoVFsFxy5YtIykpiXvvvZfx48dbBMf16NHDnG47aNAg8vLyiImJ4bnnnqOsrIxZs2Yx\nYsQIfvjhhxrXu1xKSbdS37SIVkTk2mPzlx9GRUWRlpbGgQMHqmSxnDlzxmoWy6pVqxg3bhxFRUU4\nOTnx1Vdf0bdvX44ePXpxpw+wb98+evTowcGDB6vMzFhTucpYu4SkvqlgERFpOFdll1B9Bcd17dqV\nVq1a8e6773LhwgXOnTvHu+++S/fu3S2+Y+hSCo4TERGxXzYVLPUVHOfu7s7mzZt5//33cXV1xc3N\njZSUFNavX18lDbfSvHnz8PT0NP9UzsyIiIjI9c+mgqXy6ZHJZKpV+4KCAkaOHElQUBBxcXHm4+fO\nnePRRx9l4MCBfPnll/z3v//llltuYeTIkZw7d85qX9OnT+fs2bPmn+oC5kREROT6Y9Oi20uD42ra\n0XOl4Ljly5eTnZ3N9u3bcXBwMB9r2bIlH3/8MQ8++GCV/lxcXHBxcbFluCIiInKdaJTguOLiYhwc\nHCxmaipfV1RU1OU+RERE5Dpm8y6hrKwsQkJC8Pb2rjY4Ljw8nOLiYpKTky0W51YGx2VkZNCrVy8m\nTJjAU089RUVFBfPnz+eTTz4hPT2dNm3a1DiOuq4yFhERkcZT17/fNhcsAHv37iUmJob09PQqwXHB\nwcGEhoZaPa8yOG7v3r1MmTKFbdu2ceHCBRwcHOjYsSP/+Mc/6N+/f63GoIJFRESk6anr3+96D46b\nOnUqb731Ft26dSMgIID8/Hzi4uLYs2ePeWfP119/za233kpcXBzt27dn27ZtTJo0ia+++qrWBUsl\nBcdJbSlfRUSk6boqwXFpaWn07NmTzMxMOnbsaLXf2NhY0tPTSU1NrdU4FBwntlLBIiLS+K7Z4Lii\noiISExMJDAy8YnbK2bNn8fb2tmU4IiIiYicaLDhuyZIluLm5mUPhNm7ciLOzs9W227ZtY+XKlRbh\ncpdT0q2IiIj9arDguLFjx/LNN9+wZcsWOnfuzOjRozl//nyVdt9++y2jRo1i1qxZREREVNufkm5F\nRETsl00Fy6XBcTXx9PSkc+fODBkyhKSkJDIyMkhOTrZo89133xEWFsakSZN44YUXrtifkm5FRETs\nV4MEx13OMAwMw6CkpMR8bP/+/YSGhvLwww8THx9f47VdXFzw8PCw+BERERH7YFPBAhfXppSXl9Ov\nXz8++OADDh48SHp6Om+88QYDBgzg8OHDzJs3j6+//pqjR4+ybds27r//flxdXYmKigL+V6yEh4fz\nzDPPkJubS25uLj/99FO936CIiIg0fTbnsAQGBrJ7927i4+OZOnUqJ06cwNfXl+DgYBISEmjevDlb\nt27l9ddf5/Tp07Ru3ZohQ4awbds2/Pz8AFi1ahU//fQT//znP/nnP/9p7vumm24iOzvbpvGcna7g\nOBERkeudzQULXFx0azKZzF9cWPkdQOXl5bRt25bo6GiKi4vZvXs3x44dY/HixRZbnuPi4rjnnnt4\n9tln2bVrF46OjvzmN7/h1VdftXksCo6zT8pUERGxLzY/EsrOziY4OJjU1FQWLFjAvn37SElJITQ0\nlNjYWODilxtGRkby/PPPW+0jJyeHO++8k06dOrFjxw5SUlLYv38/48eP/0U3IyIiItcnm2dYnnji\nCUwmEzt37rQIj7v55puZMGECAFOmTAFg8+bNVvtYs2YNzZo1Y/HixeZZmqVLl9KjRw8yMzPp1KmT\nrcMSERGR61iDJ91aU1JSgrOzs7lYAXB1dQXgiy++qPYcBceJiIjYpwZLur2SO+64g9zcXBYuXMiF\nCxc4ffo0zz33HAAnTpyweo6C40REROxXgyXdXsnNN9/Me++9xyuvvEKLFi3w9/cnMDCQ1q1b4+jo\naPUcBceJiIjYrwZLuq3Jb3/7W3Jzczl+/DinTp0iLi6On376icDAQKvtFRwnIiJiv65K0u2VtG7d\nGjc3N1auXEnz5s0JDw+3uQ8RERG5vtm8S2jJkiWEhITQr18/5syZQ48ePSgrK2Pjxo0kJCSQnp5u\nTq7NzMwEYN++fbi7uxMQEIC3tzcAb775JiEhIbi5ubFx40amTZvG/Pnza71wt5KC40RERK5/JqNy\nYYoN9u7dS0xMDOnp6ZSVleHo6IiPjw/Tpk1j6tSp3H333axZs6bKeYmJiYwfP57s7GzuvPNOsrKy\nqKiowNnZmaioKFauXImzs3OtxlBQUICnpydnz6pgERERaSrq+vfb5hmW7OxsoqKi8PLyYsWKFfTo\n0YPS0lI2bNjAsmXLmDp1KmFhYQwcOBC4uFj29OnTFjMnGRkZDB48mCVLltCpUye+/fZbJk6cyPPP\nP8+iRYtsGo+Sbu2H0m1FROyXzTMsUVFRpKWlceDAgSpZLGfOnLEoTDZv3kxoaGiVgsWahQsXkpCQ\nwOHDh2s1jsoKjedQwWInVLCIiDR9dZ1haZTgOGvOnj1rXt8iIiIicimbHgnVV3CctX7/+te/XvFx\nUElJCSUlJebXSroVERGxH40SHHep48ePExkZyf3338/EiROrbaekWxEREfvVaMFxcPFbm0NDQwkJ\nCWHZsmVXbKukWxEREfvVaMFxx48fZ9iwYQQHB5OYmGjxRYjWKOlWRETEfjVKcFxOTg7Dhg0jICCA\nRYsW8dNPP5n79/f3t2k8Co4TERG5/tlcsAQGBrJ7927i4+OZOnUqJ06cwNfXl+DgYBISEgBYunQp\ns2fPNp8zZMgQ4H/BcZ9++imZmZlkZmbSrl07i/7rkGMnIiIi1zmbCxa4uOjWZDKZH+OYTCYqKioo\nLy8nPz+fU6dO0aVLF3744Qd8fHyIjo5m7ty5F3NTgLvvvpvhw4eTlpbGqVOn8PPzY9SoUbz00ks2\nj0XBcU2f8lVERKQmdUq6HThwIF5eXixYsMAi6TY2NpakpCRycnJYtGgRQUFBHDlyhMmTJ5OTk0NS\nUhIADg4OjBo1ihdffBFfX18yMzOJjY0lPz+f5cuX1/tNioiISNPWoEm3lVatWsW4ceMoKirCycl6\njfTGG2+wcOHCWu/+UdLt9UMzLCIi9uOqfJdQZdJtfHy8TUm3lYOqrljJycnhww8/ZOjQodVeW8Fx\nIiIi9sumbc11SbrNy8tj7ty5TJo0qcp7Y8aMoUWLFtx44414eHjwzjvvVNuPguNERETsV4Mm3RYU\nFDBy5EiCgoKIi4ur8v5rr73G7t27+eijjzh06BDPPPNMtX0pOE5ERMR+2fRI6NKk2+jo6Cu2LSws\nJHGrjBcAACAASURBVDIyEnd3d5KTk2nWrFmVNv7+/vj7+9OtWzdatWrF4MGDmTFjBm3atKnS1sXF\nBRcXF1uGKyIiIteJBkm6LSgoICIiAmdnZ1avXk3z5jWviq2oqACwWKciIiIiAnXYJZSVlUVISAje\n3t5Wk2537txJeHg4xcXFJCcnWyzO9fX1xdHRkXXr1vHjjz/St29f3Nzc2L9/P9OmTcPb25svvvii\nVuOo6ypjERERaTxXZZcQ1Jx0+/XXX7Njxw4AOnXqZHHuHXfcwfPPP4+rqyuLFy8mLS2N0tJSTCYT\nfn5+PPfcc7YOR0REROyAzTMstXFpuNzs2bMtwuWWLVtGRkYGERERnDlzhjfffBMfHx+WL1/OrFmz\n+Oqrr+jdu3eN11AOS9OgjBUREblUXWdYGqRgqU24nJubGwkJCcTExJjfa9WqFS+//DKPPfZYjddQ\nwdI0qGAREZFL1bVgsWnRbW1UhsvFxsZeMVwuJCSElStXkp+fT0VFBf/61784f/48w4YNs9pvSUkJ\nBQUFFj8iIiJiH+q9YKltuNy///1vSktLadWqFS4uLjz++OMkJydXWfdSScFxIiIi9qveC5bahsvN\nmDGDM2fOsGnTJr766iueeeYZRo8ezb59+6y2V3CciIiI/bJ5l1BNahMud+jQId58802+/fZbbr75\nZgB69uzJ1q1bWbx4MUuXLq1yjoLjRERE7Fe9z7DUJlyuuLj44sUdLC/v6OhoDpATERERqdQgu4Rq\nCpdLS0sjKCiINm3asGjRIlq1asVHH33EtGnTWLNmDVFRUTVeQ8FxIiIiTc9VC44DyM3NJT4+nrVr\n13L8+HH8/Pzo1asXU6ZMoXfv3rz66qu0aNGC77//ngceeADDMGjdujV9+/YlISGBZs2asW7dOsaM\nGUNISAjl5eX/r717j47p3PsA/p1MrkyESEKQFHFXoeIkRFsiLsFRuhy0SKV1N+pIlVdKJaFBU3Vc\nStq0hNatpGKpSzSl6QUVFbm0JiqSSJEpcctNEkme9w9v5jVMLntOLpPM97NW1jJ7nr33bx5Z5mf2\ns78DuVyOIUOGVKtZISIiIuMiuWF5MhQuNDRUKxROqVQiMjISN2/exIYNG9CjRw9cu3YNc+bMgaur\nKyIjIzXH+fbbb5GVlYUvv/wSHh4eyM/PR0ZGhuQXYLPGhjksdYzZKkREVNckXxKqTijc0w4cOICp\nU6ciPz8fpqamuHfvHtq2bYtvv/0W3t7eehXO4Lj6w4aFiIj0VSfBcdUNhXtaeVGmpo8/0ImJiUFZ\nWRlu3LiB7t27o127dpg4cSJvVSYiIiKdJDUs1Q2Fe1J2djZWrVqFWbNmabalpaWhrKwMq1evxoYN\nGxAZGYm7d+9i2LBhKC4u1nkcJt0SEREZL0kNS3VD4crl5ORg9OjR6NGjB4KCgjTby8rK8OjRI2za\ntAkjRoxA//79sXfvXly5cgU//PCDzmMx6ZaIiMh4SWpYngyFq0pubi58fHxgbW2NqKgomJmZaZ5z\ndHQEAPTo0UOzzd7eHnZ2dsjMzNR5PCbdEhERGS9JDUt1QuGAx5+sDB8+HObm5jh8+DAsLbVXxQ4c\nOBAAcPnyZc22u3fvIjs7G88995zOc1tYWKBZs2ZaP0RERGQcJN8lVFUoXFxcHIYNG4aCggJERUVp\nLc61t7eHXC4HAIwbNw6pqakIDw9Hs2bNEBAQgLS0NCQkJGh9GlMRBscRERE1PPq+f+uVdJuVlYWQ\nkBAcOXIEWVlZsLe3h5ubG/z9/QEAXl5eOvdLT09H+/btNQX7+/vj4MGDMDExwaBBg7Bx48Zqr01h\nw0JERNTw1GnDUh2VpeF6e3sjPDwce/bsQXx8PHJzc3Hv3r0Kb4vWhTksdYvZK0REVBPqJIelujIy\nMuDm5oZTp04hNDQUycnJiI6OhpeXF5RKJQCgoKAAPj4+eO+992qjBCIiImpE9PouoarMmzcPMpkM\ncXFxWmtYevbsibfeegsAsHDhQgBAbGxsbZRAREREjUiNNyzlabghISGS0nCrUlRUhKKiIs1jBscR\nEREZjxq/JKRPGm51MDiOiIjIeNV4wyI1Dbe6GBxHRERkvGq8YZGShisFg+OIiIiMV403LNVNwyUi\nIiKqrlq5S2jr1q3w9PSEu7u7zjRclUoFtVoNtVqN1NRUAEBycjKsra3h7OwMW1vbap/rQQCD44iI\niBq7WmlYOnTogOjoaPj6+uK1115DSUkJ5HI57OzssHjxYgDAp59+iuDgYM0+L7/8MgAgIiICfn5+\ntVEWERERNVC1knSbkZGBgQMHonnz5ggODoarqysePXqEEydOIDw8HCkpKZqx//nPfxATE4Pjx48j\nKioK48aNq9Y5mHRbOSbTEhGRIdI36bbeguMAIDExEevXr8f58+fh6OhYG6UQERFRI1BvwXEFBQV4\n/fXX8cknn6B169ZVHpfBcURERMar3oLj/P394enpibFjx1bruAyOIyIiMl71Ehx3+PBhnDp1Chs2\nbKj2cRkcR0REZLzqJTju1KlTuHr1Kpo3bw5TU1OYmj6+MjV+/HgMHjxY5z4MjiMiIjJetXKX0MiR\nI5GcnIzLly8/s47l/v37KCwsRHZ2ttb2Xr16YePGjRgzZgw6dOhQ5Tl4l1DleJcQEREZIoO6S6g6\nwXG6Fto6OztXq1l5EoPjiIiIGr9aC46Lj49HSEgIFi1ahKysLNjb28PNzQ1hYWG1cUoiIiJqxPRq\nWNRqNUJCQnD06FHcuHEDDg4O6NOnDxYuXAhvb2/Mnj0b33//PW7evAmFQgEfHx98+OGHWncO6VqU\nW1hYKLkWmzU2vCSkAy8JERFRYyK5YXkyxTY0NFQrxVapVCIlJQVubm6YMmUKnJ2dcffuXQQFBWH4\n8OFIT0+HXC7XHCsiIgI+Pj6ax+UZLURERERPkrzodtSoUUhKSqpwQa2upiMpKQm9e/dGamoqXFxc\nHp9YJpMUxf80LrqtHD9hISIiQ6TvoltJtzWXp9gqlcpKU2yflJ+fj4iICHTo0OGZsDelUgk7Ozu4\nu7tj+/btqKx3KioqQk5OjtYPERERGQdJDUt1U2yBx3cKKRQKKBQKREdHIyYmBubm5prnV65cif37\n9yMmJgbjx4/HvHnzsHnz5gqPx6RbIiIi4yXpktC5c+fQv3//al3KefDgAW7duoWsrCysW7cON27c\nwOnTp2Fpqfv6zYoVKxAREVFhgq2u7xJycnLiJaEK8JIQEREZojq5JFSdFNtyNjY26Ny5M15++WVE\nRkYiJSUFUVFRFY738PDA9evXK7xTiEm3RERExktSw2Jra4sRI0Zgy5YtyM/Pf+b5+/fv69xPCAEh\nhNYnJE9LSEhAixYtKvwEhoiIiIyX5Nuaq0qxPXr0KL7++msMHz4c9vb2uH79OtauXQsrKyuMGjUK\nAPDtt9/i1q1b6N+/PywsLBATE4PVq1fj3XfflfwCmHRLRETU+EluWDp06IDo6Gj4+vritddeQ0lJ\nCeRyOezs7LB48WJYWloiLCwMy5cvR1lZGUxMTODo6Ihdu3bBwcEBAGBmZoalS5fi7t27KCsrg6Wl\nJTZs2ICZM2dKfgEMjtPGtStERNQYSc5heTI4Ljg4WCs4Ljw8HCkpKQgPD0e3bt20guMSEhK0guMW\nLFiArl274ty5c0hKSkJCQoKkwpnDohsbFiIiMmT6Lrqtt+C4ckFBQTh06BAblhrChoWIiAxZnXxb\nc3lwXEhISI0Ex0mh67ZmIiIiMg71FhwnFYPjiIiIjJekhqX86pGub1p+2pQpU3Dx4kX8+OOP6Ny5\nMyZOnKjXtzGXCwgIwIMHDzQ/FQXMERERUeNjMMFxVWFwHBERkfEymOA4IiIioorUS3Ac8Hg9TF5e\nHtRqNR4+fKi5S6hHjx6S1rowOI6IiKjxk3xbMwAkJibC19cXKpXqmeA4Hx8fjB49GtevX0dpaSnk\ncjlcXFywe/du9OvXDwCwY8cOvPnmmzqPff78ec24yuh7WxQRERHVnzrLYakqOC4yMhKBgYHw8/ND\njx49cO3aNcyZMweurq6IjIwEADx8+BAPHjzQOq6fnx8KCwsRGxtbrTqYw/IsZrAQEZGhM+jguAMH\nDmDq1KnIz8+HqemzV6Fu376Ntm3bYtu2bfD19a1WHWxYnsWGhYiIDJ2+DYukRbflwXFKpbLawXEA\nNEXpalYA4Msvv0STJk3wr3/9S0o5REREZCQkLbqVEhxXLjs7G6tWrcKsWbMqHLN9+3ZMnjwZVlZW\nFY5h0i0REZHxqrXgOOBxUzF69Gj06NEDQUFBOsecPXsWly5dwvTp0ys9FpNuiYiIjFetBcfl5ubC\nx8cH1tbWiIqKgpmZmc5xX3zxBfr06QM3N7dKj8ekWyIiIuNVK8FxOTk5GD58OMzNzXH48GFYWupe\nFZuXl4f9+/dX+ekKwKRbIiIiYyb5LqH09HR4enrC1tZWZ3BcXFwchg0bhoKCAkRFRWktzrW3t4dc\nLtc83rZtG+bPn4+bN2+iRYsWkgpnDgsREVHDU2e3NQNAVlYWQkJCcOTIEWRlZcHe3h5ubm7w9/cH\nAHh5eencLz09He3bt9c89vT0RIcOHbB7926pJbBhISIiaoD0ff+WHM0PPF50K5PJYGJionlcVlaG\n0tJSeHt747PPPsOePXsQHx+P3Nxc3Lt375lbntu3b49r167h7Nmz2LNnD4DHC2uXLl0qqRabNTZG\nk8PCnBUiIjJWkhuWJ5NuQ0NDtZJulUolUlJSUFBQAB8fH/j4+CAgIKDCY61cuRIzZ87UPLa2ttbv\nVRAREVGjJrlhmTdvHmQyGeLi4rTWp/Ts2RNvvfUWAGDhwoUAUGXMvrW1NVq3bi21BCIiIjIydZJ0\nW5G1a9eiZcuWeOGFF/DRRx+hpKSkwrFFRUXIycnR+iEiIiLjUOtJtxVZsGAB+vbtC1tbW5w5cwYB\nAQHIysrC+vXrdY5fs2YNgoOD/+vzEhERUcMjqWGRmnRbmXfeeUfzZ1dXV5ibm2P27NlYs2YNLCws\nnhkfEBCgtU9OTg7TbomIiIxErSXdSuXh4YGSkhJkZGTofJ7BcURERMarVpJu9ZGQkAATExM4ODjo\nfQwiIiJqnCTfJbR161Z4enrC3d1dZ9KtSqWCWq2GWq1GamoqACA5ORnW1tZwdnaGra0tzp49i3Pn\nzsHLywvW1tY4e/Ys/P39MXXqVMmJtw8CGBxHRETU2NV40u3gwYMRFBSkc4Fs79698fHHH6NFixYY\nOXIksrOzUVZWBrlcji5dumDfvn1wdXWtVg1MuiUiImp46jSavypPhssFBwdrhcuFh4cjJSUF4eHh\n6NatG5ydnXH37l0EBQUhISEB6enpWt83VJHyF4ylaPRJt0y4JSKixsKgGpZRo0YhKSkJly9ffiav\n5f79+zrzWpKSktC7d2+kpqbCxcWlynOwYSEiImp46vS7hCpTHi4XEhJS7XC5/Px8REREoEOHDhXe\nqlxUVISioiLNYwbHERERGQ9JdwlVh5Rwua1bt0KhUEChUCA6OhoxMTEwNzfXOXbNmjWwsbHR/DCD\nhYiIyHjUeMMiJVxuypQpuHjxIn788Ud07twZEydORGFhoc6xAQEBePDggebnr7/+qtG6iYiIyHDV\neMMiJVzOxsYGnTt3xssvv4zIyEikpKQgKipK51gGxxERERmvGm9Y9A2XE0JACKG1ToWIiIgIqKW7\nhNLT0+Hp6QlbW1ud4XJHjx7F119/jeHDh8Pe3h7Xr1/H2rVrcfr0aahUqmql3TKHhYiIqOExqNua\nASAxMRG+vr5QqVQoKSmBXC6HnZ0dFi9ejBdffBH9+/fXud/+/fsxYcKEKo/PhoWIiKjhMaiGparg\nuD/++AO3b9/W2ic8PByhoaFQq9VQKBRVnoM5LERERA2PweSwAMC8efMgk8kQFxenlcXSs2dPvPXW\nW5DL5WjdurXWPlFRUZg0aVK1mhUiIiIyLjW+6LY8OE6pVFY7OO7ChQtISEjA9OnTa7ocIiIiagRq\n/BMWKcFx5bZt24bu3bvD09OzwjFMuiUiIjJe9RocBwAPHz7Enj17qvx0hUm3RERExqteg+MAIDIy\nEgUFBXjjjTcqHcekWyIiIuNV78Fx27ZtwyuvvAJ7e/tKj8ukWyIiIuNV4w0L8PhLDUtLS+Hu7o5v\nvvkGV65cgUqlwqZNmzBgwADNuNTUVPz000+YMWNGbZRBREREjUSt3NbcoUMHxMfHIyQkBIsWLUJW\nVhbs7e3h5uaGsLAwzbjt27ejbdu2GD58uN7nehDA4DgiIqLGTq+GRa1WIyQkBEePHsWNGzfg4OCA\nPn36YOHChfD29kZ4eDj27NmD+Ph45Obm4t69e8/czhwSEoLY2FjcuXMHtra2FX7HUFVs1tg0yuA4\nhsURERH9P8mXhDIyMuDm5oZTp04hNDQUycnJiI6OhpeXF5RKJQCgoKAAPj4+eO+99yo8TnFxMSZM\nmIC5c+fqXz0REREZBcmfsFSVYgsACxcuBADExsZWeJzg4GAAwI4dO6SWQEREREZGUsNSnmIbEhJS\n7RTbmsLgOCIiIuMl6ZKQPim2NYXBcURERMZLUsMiNcW2JjE4joiIyHhJalikptjWJAbHERERGS9J\nDYvUFFsiIiKimiD5LqGtW7fC09MT7u7uWLlyJVxdXVFSUoKYmBiEhYVBpVJBrVZDrVYjNTUVAJCc\nnAxra2s4OzvD1tYWAJCZmYm7d+8iMzMTpaWlSEhIAAB06tQJCoWi2vUwOI6IiKjxk4nyhSkSZGVl\nISQkBEeOHNFKsfX398fgwYMRFBSkuW35SREREfDz8wMA+Pn5YefOnc+M+eGHHzB48OAqa8jJyYGN\njQ0ePGDDQkRE1FDo+/6tV8NiCNiwEBERNTz6vn/XypcfEhEREdUkNixERERk8NiwEBERkcFjw0JE\nREQGjw0LERERGTw2LERERGTw2LAQERGRwWPDQkRERAaPDQsREREZPDYsREREZPDYsBAREZHBY8NC\nREREBo8NCxERERk80/ouQF/lXzKdk5NTz5UQERFRdZW/b5e/j1dXg21Y7ty5AwBwcnKq50qIiIhI\nqtzcXNjY2FR7fINtWGxtbQEAmZmZkl4w/fdycnLg5OSEv/76C82aNavvcowG573+cO7rB+e9/tTm\n3AshkJubizZt2kjar8E2LCYmj5ff2NjY8Be5njRr1oxzXw847/WHc18/OO/1p7bmXp8PGrjoloiI\niAweGxYiIiIyePKgoKCg+i5CX3K5HIMHD4apaYO9stVgce7rB+e9/nDu6wfnvf4Y2tzLhNT7ioiI\niIjqGC8JERERkcFjw0JEREQGjw0LERERGTw2LERERGTwDLph2bJlC9q3bw9LS0t4eHggLi6u0vEH\nDhxAt27dYGlpiV69euHYsWN1VGnjI2XuP//8c7z00kto0aIFWrRogaFDh1b5d0W6Sf2dL7dv3z7I\nZDKMGzeulitsvKTO/f3796FUKuHo6AhLS0t06dKF/+boQeq8b9iwAV27doWVlRWcnJzg7++PwsLC\nOqq2cfjpp58wZswYtGnTBjKZDIcOHapyn9jYWPTt2xcWFhbo1KkTduzYUfuFPk0YqH379glzc3Ox\nfft28ccff4iZM2eK5s2bi7///lvn+DNnzgi5XC5CQ0PFpUuXxPvvvy/MzMxEcnJyHVfe8Emd+8mT\nJ4stW7aIixcvCpVKJfz8/ISNjY24fv16HVfesEmd93IZGRmibdu24qWXXhJjx46to2obF6lzX1RU\nJPr16ydGjRolfvnlF5Geni5iY2NFQkJCHVfesEmd9927dwsLCwuxe/dukZ6eLk6cOCEcHR2Fv79/\nHVfesB07dkwsW7ZMfPPNNwKAiIqKqnR8WlqaaNKkiXjnnXfEpUuXxObNm4VcLhfR0dF1VPFjBtuw\nuLu7C6VSqXlcWloq2rRpI9asWaNz/MSJE8Xo0aO1tnl4eIjZs2fXap2NkdS5f1pJSYmwtrYWO3fu\nrK0SGyV95r2kpEQMHDhQfPHFF2LatGlsWPQkde7DwsJEx44dRXFxcV2V2ChJnXelUimGDBmite2d\nd94RAwcOrNU6G7PqNCxLliwRPXv21No2adIkMWLEiNos7RkGeUmouLgYFy5cwNChQzXbTExMMHTo\nUJw9e1bnPmfPntUaDwAjRoyocDzpps/cP62goACPHj3SfEElVU3feV+5ciXs7e0xffr0uiizUdJn\n7g8fPowBAwZAqVSiVatWeP7557F69WqUlpbWVdkNnj7z7unpiQsXLmguG6WlpeHYsWMYNWpUndRs\nrAzl/dUw4uuekp2djdLSUrRq1Upre6tWrZCSkqJzH7VarXO8Wq2utTobI33m/mn/8z//gzZt2jzz\nC04V02feT58+jW3btiEhIaEuSmy09Jn7tLQ0nDp1ClOmTMGxY8dw5coVKJVKlJSUYMWKFXVRdoOn\nz7xPnjwZ2dnZePHFFyGEQElJCebMmYP33nuvLko2WhW9v+bk5ODhw4ewsrKqkzoM8hOWigghIJPJ\nam08Vay6c7l27Vrs27cPUVFRsLS0rIPKGreK5j03NxdTp07F559/Djs7u3qorPGr7He+rKwMDg4O\nCA8Ph5ubG1577TUsW7YMYWFhdVxl41PZvMfGxmL16tXYunUr4uPjcfDgQRw9ehSrVq2q4ypJ/F9I\nfl2+xxrkJyx2dnaQy+X4+++/tbbfunXrmS6vXOvWrSWNJ930mfty69atw9q1a/H999/D1dW1Nsts\ndKTO+9WrV5GRkYExY8ZotpWVlQEATE1NcfnyZbi4uNRu0Y2EPr/zjo6OMDMzg1wu12zr3r071Go1\niouLYW5uXqs1Nwb6zPv7778PX19fzJgxAwDQq1cv5OfnY9asWVi2bBlMTBrU/8EbjIreX5s1a1an\n/zE1yL9dc3NzuLm54eTJk5ptZWVlOHnyJAYMGKBznwEDBmiNB4CYmJgKx5Nu+sw9AHz00UdYtWoV\noqOj0a9fv7ootVGROu/dunVDcnIyEhISND+vvPIKvLy8kJCQACcnp7osv0HT53d+4MCBSE1N1TSJ\nAPDnn3/C0dGRzUo16TPvBQUFzzQlcrkc4vENJLVarzEzmPfXOl3iK0H57W47duwQly5dErNmzRLN\nmzcXarVaCCGEr6+vWLp0qWb86dOnhVwuF+vWrRMqlUoEBgbytmY9SZ37Dz/8UJibm4vIyEiRlZWl\n+cnNza2vl9AgSZ33p/EuIf1JnfvMzEyhUCjE/PnzxeXLl8WRI0eEg4OD+OCDD+rrJTRIUuc9MDBQ\nWFtbi71794q0tDTx3XffCRcXFzFx4sT6egkNUm5urrh48aK4ePGiACDWr18vLl68KK5duyaEEGLp\n0qXC19dXMz4tLU1YWVmJxYsXC5VKJbZs2cLbmp+2efNm4ezsLMzNzYW7u7v49ddfNc8NGjRITJs2\nTWv8/v37RZcuXYS5ubno2bOnOHr0aB1X3HhImfvnnntOAHjmJzAwsO4Lb+Ck/s4/iQ3Lf0fq3J85\nc0Z4eHgICwsL0bFjRxESEiJKSkrquOqGT8q8P3r0SAQFBQkXFxdhaWkpnJycxLx588S9e/fqofKG\n64cfftD5b3b5XE+bNk0MGjRIa59Tp06JPn36CHNzc9GxY0cRERFR53XLhODnaERERGTYDHINCxER\nEdGT2LAQERGRwWPDQkRERAaPDQsREREZPDYsREREZPDYsBAREZHBY8NCREREBo8NC5ERGzx4MBYu\nXPhfHWPHjh1o3rx5DVVERKQbGxYiA3X79m3MnTsXzs7OsLCwQOvWrTFixAicPn26vkuTTCaT4dCh\nQ/VdRoWCgoLQp0+f+i6DiCphkN/WTETA+PHjUVxcjJ07d6Jjx474+++/cfLkSdy5c6e+S2s0hBAo\nLS2t7zKIqBr4CQuRAbp//z5+/vlnfPjhh/Dy8sJzzz0Hd3d3BAQE4JVXXtEaN3v2bLRq1QqWlpZ4\n/vnnceTIEQDAnTt38Prrr6Ndu3Zo0qQJevXqhb1791Z63qKiIrz77rto27YtmjZtCg8PD8TGxmqN\n2bFjB5ydndGkSRO8+uqrkhuojIwMyGQy7N+/Hy+99BKsrKzwj3/8A3/++SfOnz+Pfv36QaFQYOTI\nkbh9+7ZmPz8/P4wbNw7BwcGwt7dHs2bNMGfOHBQXF2vVv2DBAjg4OMDS0hIvvvgizp8/r3k+NjYW\nMpkMx48fh5ubGywsLLBr1y4EBwcjMTERMpkMMpkMO3bsAACsX78evXr1QtOmTeHk5IR58+YhLy9P\nay6aN2+OEydOoHv37lAoFPDx8UFWVpbWa96+fTt69uwJCwsLODo6Yv78+Zrn7t+/jxkzZmhe05Ah\nQ5CYmChpTomMARsWIgOkUCigUChw6NAhFBUV6RxTVlaGkSNH4vTp09i1axcuXbqEtWvXQi6XAwAK\nCwvh5uaGI0eO4Pfff8esWbPg6+uLc+fOVXje+fPn4+zZs9i3bx+SkpIwYcIE+Pj44MqVKwCAc+fO\nYfr06Zg/fz4SEhLg5eWFDz74QK/XGBgYiOXLlyM+Ph6mpqaYPHkylixZgo0bN+Lnn39GamoqVqxY\nobXPyZMnoVKpEBsbi7179+LgwYMIDg7WPL9kyRJ888032LlzJ+Lj49GpUyeMGDECd+/e1TrO0qVL\nsXbtWqhUKgwbNgyLFi1Cz549kZWVhaysLEyaNAkAYGJigk2bNuH333/Hzp07cerUKSxZskTrWAUF\nBVi3bh2++uor/PTTT8jMzMS7776reT4sLAxKpRKzZs1CcnIyDh8+jE6dOmmenzBhAm7duoXjx4/j\nwoUL6Nu3L7y9vZ+pmcjo1fnXLRJRtURGRooWLVoIS0tL4enpKQICAkRiYqLm+RMnTggTExNx+fLl\nah9z9OjRYtGiRZrHgwYNEv/+97+FEEJcu3ZNyOVycePGDa19vL29RUBAgBBCiNdff12MGjVKhVEP\nTQAABfpJREFU6/lJkyYJGxubSs8LQERFRQkhhEhPTxcAxBdffKF5fu/evQKAOHnypGbbmjVrRNeu\nXTWPp02bJmxtbUV+fr5mW1hYmFAoFKK0tFTk5eUJMzMzsXv3bs3zxcXFok2bNiI0NFQI8f/fUnvo\n0CGt+gIDA0Xv3r0rfQ1CCHHgwAHRsmVLzeOIiAgBQKSmpmq2bdmyRbRq1UrzuE2bNmLZsmU6j/fz\nzz+LZs2aicLCQq3tLi4u4rPPPquyHiJjwk9YiAzU+PHjcfPmTRw+fBg+Pj6IjY1F3759NZcrEhIS\n0K5dO3Tp0kXn/qWlpVi1ahV69eoFW1tbKBQKnDhxApmZmTrHJycno7S0FF26dNF8wqNQKPDjjz/i\n6tWrAACVSgUPDw+t/QYMGKDX63N1ddX8uVWrVgCAXr16aW27deuW1j69e/dGkyZNtM6dl5eHv/76\nC1evXsWjR48wcOBAzfNmZmZwd3eHSqXSOk6/fv2qVeP3338Pb29vtG3bFtbW1vD19cWdO3eQn5+v\nGdOkSRO4uLhoHjs6OmrqvnXrFm7evAlvb2+dx09MTEReXh5atmypNefp6emaOSeix7jolsiAWVpa\nYtiwYRg2bBjef/99zJgxA4GBgfDz84OVlVWl+3700UfYuHEjNmzYoFmHsXDhQq01H0/Ky8uDXC7H\nhQsXNJeVyikUCgCPF6nKZLIaeW1mZmaaP5cf8+ltZWVl1TqWTCaDEELrWOV01dy0adMqj5mRkYF/\n/vOfmDt3LkJCQmBra4tffvkF06dPx6NHj3S+jqdrqervKC8vD46Ojs+sEwLAW8WJnsJPWIgakB49\nemj+d+/q6orr16/jzz//1Dn29OnTGDt2LKZOnYrevXujY8eOmrUourzwwgsoLS3FrVu30KlTJ62f\n1q1ba87/66+/au339OPalJiYiIcPH2qdW6FQoF27dujUqRPMzc3xyy+/aJ5/9OgRfvvtN3Tv3r3S\n45qbmz9zt9CFCxdQWlqKjz/+GP3790eXLl1w8+ZNSfVaW1ujffv2OHnypM7n+/btC7VaDVNT02fm\n3M7OTtK5iBo7NixEBujOnTsYMmQIdu3ahaSkJKSnp+PAgQMIDQ3F2LFjAQCDBg3Cyy+/jPHjxyMm\nJgbp6ek4fvw4oqOjAQCdO3dGTEwMzpw5A5VKhdmzZ0OtVld4zi5dumDKlCl44403cPDgQaSnpyMu\nLg5r1qzB0aNHAQALFixAdHQ01q1bhytXruCTTz7RnK8uFBcXY/r06bh06RKOHz+OwMBAzJ8/HyYm\nJmjatCnmzp2LxYsXIzo6GpcuXcLMmTNRUFCA6dOnV3rc9u3bIz09HQkJCcjOzkZRURE6deqEkpIS\nbN68GWlpafjqq6/w6aefSq45KCgIH3/8MTZt2oQrV64gPj4emzdvBgAMHToUAwYMwLhx4/Ddd98h\nIyMDZ86cwbJly/Dbb7/pNUdEjVb9LqEhIl0KCwvF0qVLRd++fYWNjY1o0qSJ6Nq1q1i+fLkoKCjQ\njLtz54548803RcuWLYWlpaV4/vnnxZEjRzTPjR07VigUCuHg4CCWL18u3njjDTF27FjN/k8uuhXi\n8SLVFStWiPbt2wszMzPRunVr8eqrr4qkpCTNmG3btol27doJKysrMWbMGLFu3Tq9Ft1evHhR83z5\nYth79+5ptkVERGgdd9q0aWLs2LFixYoVomXLlkKhUIiZM2dqLVh9+PChePvtt4WdnZ2wsLAQAwcO\nFHFxcZWep3y+x48fL5o3by4AiIiICCGEEOvXrxeOjo7CyspKjBgxQnz55Zda+z9doxBCREVFiaf/\naf30009F165dhZmZmXB0dBRvv/225rmcnBzx9ttvizZt2ggzMzPh5OQkpkyZIjIzMyudUyJjIxPi\n/y62EhEZMD8/P9y/f9+gE3OJqPbwkhAREREZPDYsREREZPB4SYiIiIgMHj9hISIiIoPHhoWIiIgM\nHhsWIiIiMnhsWIiIiMjgsWEhIiIig8eGhYiIiAweGxYiIiIyeGxYiIiIyOCxYSEiIiKD979S7S/R\n2VUJrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc7b66a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "variables = model._model_json['output']['variable_importances']['variable']\n",
    "y_pos = np.arange(len(variables))\n",
    "scaled_importance =model._model_json['output']['variable_importances']['scaled_importance']\n",
    "ax.barh(y_pos, scaled_importance, align='center', color='green', ecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(variables)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Scaled Importance')\n",
    "ax.set_title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las 6 variables mas importantes c18, c17, c22, c21, c24 y c20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Random Forest para Landsat usando Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la Precision estimada es 0.972717023675\n"
     ]
    }
   ],
   "source": [
    "url='http://academic.uprm.edu/eacuna/landsat.txt'\n",
    "data = pd.read_table(url, header=None,delim_whitespace=True)\n",
    "y=data.iloc[:,36]-1\n",
    "names=['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13',\n",
    "            'C14','C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26','C27',\n",
    "           'C28','C29', 'C30','C31','C32','C33','C34','C35','C36','C37']\n",
    "X=data.iloc[:,0:36]\n",
    "clf = RandomForestClassifier(n_estimators=50,max_depth=10, oob_score=True, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print \"la Precision estimada es\", clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      1072\n",
      "          1       1.00      1.00      1.00       479\n",
      "          2       0.95      1.00      0.97       961\n",
      "          3       0.98      0.80      0.88       415\n",
      "          4       1.00      0.93      0.97       470\n",
      "          5       0.96      0.99      0.98      1038\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898534385569\n"
     ]
    }
   ],
   "source": [
    "#Estimacion del error usando out-of-bag\n",
    "print clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0151426   0.02236955  0.00933652  0.01346124  0.03756244  0.02431621\n",
      "  0.00885772  0.01182643  0.02164484  0.01734902  0.00778902  0.02265685\n",
      "  0.03495008  0.04105357  0.02258549  0.03426316  0.08886045  0.05336134\n",
      "  0.02783217  0.04746638  0.04815995  0.04380354  0.01428742  0.02988966\n",
      "  0.04441645  0.02346674  0.00710566  0.02775813  0.02947498  0.02382096\n",
      "  0.00788551  0.03829542  0.03270221  0.03890708  0.00804944  0.01929177]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las variables mas importante son 17, 18, 21, 20, 25 y 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Aplicando Random Forest   a un dataset con missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944074199195\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0482756745585\n",
      "RMSE: 0.219717260493\n",
      "LogLoss: 0.168984138878\n",
      "Mean Per-Class Error: 0.0581370035895\n",
      "AUC: 0.986552904841\n",
      "Gini: 0.973105809683\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.406550936827: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>23638.0</td>\n",
       "<td>1082.0</td>\n",
       "<td>0.0438</td>\n",
       "<td> (1082.0/24720.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>711.0</td>\n",
       "<td>7130.0</td>\n",
       "<td>0.0907</td>\n",
       "<td> (711.0/7841.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>24349.0</td>\n",
       "<td>8212.0</td>\n",
       "<td>0.0551</td>\n",
       "<td> (1793.0/32561.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  ----------------\n",
       "<=50K  23638    1082    0.0438   (1082.0/24720.0)\n",
       ">50K   711      7130    0.0907   (711.0/7841.0)\n",
       "Total  24349    8212    0.0551   (1793.0/32561.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4065509</td>\n",
       "<td>0.8883075</td>\n",
       "<td>203.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3057791</td>\n",
       "<td>0.9245361</td>\n",
       "<td>240.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5479297</td>\n",
       "<td>0.9002645</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4099955</td>\n",
       "<td>0.9450570</td>\n",
       "<td>202.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9997935</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1272799</td>\n",
       "<td>1.0</td>\n",
       "<td>313.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9997935</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4065509</td>\n",
       "<td>0.8521938</td>\n",
       "<td>203.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3619990</td>\n",
       "<td>0.9398463</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3342153</td>\n",
       "<td>0.9418630</td>\n",
       "<td>229.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.406551     0.888307  203\n",
       "max f2                       0.305779     0.924536  240\n",
       "max f0point5                 0.54793      0.900265  158\n",
       "max accuracy                 0.409996     0.945057  202\n",
       "max precision                0.999794     1         0\n",
       "max recall                   0.12728      1         313\n",
       "max specificity              0.999794     1         0\n",
       "max absolute_mcc             0.406551     0.852194  203\n",
       "max min_per_class_accuracy   0.361999     0.939846  219\n",
       "max mean_per_class_accuracy  0.334215     0.941863  229"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 24.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100120</td>\n",
       "<td>0.9971092</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0415763</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200240</td>\n",
       "<td>0.9906771</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.0831527</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300052</td>\n",
       "<td>0.9830752</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0414488</td>\n",
       "<td>0.1246015</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400172</td>\n",
       "<td>0.9710523</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.1661778</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500292</td>\n",
       "<td>0.9518182</td>\n",
       "<td>4.1526591</td>\n",
       "<td>4.1526591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0415763</td>\n",
       "<td>0.2077541</td>\n",
       "<td>315.2659100</td>\n",
       "<td>315.2659100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000276</td>\n",
       "<td>0.8125151</td>\n",
       "<td>4.1271514</td>\n",
       "<td>4.1399091</td>\n",
       "<td>0.9938575</td>\n",
       "<td>0.9969297</td>\n",
       "<td>0.2063512</td>\n",
       "<td>0.4141053</td>\n",
       "<td>312.7151366</td>\n",
       "<td>313.9909148</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500261</td>\n",
       "<td>0.6947983</td>\n",
       "<td>3.8873787</td>\n",
       "<td>4.0557496</td>\n",
       "<td>0.9361179</td>\n",
       "<td>0.9766633</td>\n",
       "<td>0.1943630</td>\n",
       "<td>0.6084683</td>\n",
       "<td>288.7378666</td>\n",
       "<td>305.5749553</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000246</td>\n",
       "<td>0.5585388</td>\n",
       "<td>3.3797748</td>\n",
       "<td>3.8867818</td>\n",
       "<td>0.8138821</td>\n",
       "<td>0.9359742</td>\n",
       "<td>0.1689835</td>\n",
       "<td>0.7774519</td>\n",
       "<td>237.9774759</td>\n",
       "<td>288.6781801</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000215</td>\n",
       "<td>0.3068333</td>\n",
       "<td>1.9156308</td>\n",
       "<td>3.2297987</td>\n",
       "<td>0.4613022</td>\n",
       "<td>0.7777664</td>\n",
       "<td>0.1915572</td>\n",
       "<td>0.9690091</td>\n",
       "<td>91.5630825</td>\n",
       "<td>222.9798735</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000184</td>\n",
       "<td>0.1515194</td>\n",
       "<td>0.2984405</td>\n",
       "<td>2.4970154</td>\n",
       "<td>0.0718673</td>\n",
       "<td>0.6013052</td>\n",
       "<td>0.0298431</td>\n",
       "<td>0.9988522</td>\n",
       "<td>-70.1559512</td>\n",
       "<td>149.7015437</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000154</td>\n",
       "<td>0.0626722</td>\n",
       "<td>0.0114785</td>\n",
       "<td>1.9999386</td>\n",
       "<td>0.0027641</td>\n",
       "<td>0.4816043</td>\n",
       "<td>0.0011478</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.8521520</td>\n",
       "<td>99.9938579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000123</td>\n",
       "<td>0.0218653</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666325</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4013410</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6632543</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000092</td>\n",
       "<td>0.0066500</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285526</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3440091</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8552626</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000061</td>\n",
       "<td>0.0008007</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2499904</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3010096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.9990403</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9699026</td>\n",
       "<td>0.0000034</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0310313</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2482822</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>3.1031316</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2408096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010012                    0.997109           4.15266    4.15266            1                1                           0.0415763       0.0415763                  315.266   315.266\n",
       "    2        0.020024                    0.990677           4.15266    4.15266            1                1                           0.0415763       0.0831527                  315.266   315.266\n",
       "    3        0.0300052                   0.983075           4.15266    4.15266            1                1                           0.0414488       0.124601                   315.266   315.266\n",
       "    4        0.0400172                   0.971052           4.15266    4.15266            1                1                           0.0415763       0.166178                   315.266   315.266\n",
       "    5        0.0500292                   0.951818           4.15266    4.15266            1                1                           0.0415763       0.207754                   315.266   315.266\n",
       "    6        0.100028                    0.812515           4.12715    4.13991            0.993857         0.99693                     0.206351        0.414105                   312.715   313.991\n",
       "    7        0.150026                    0.694798           3.88738    4.05575            0.936118         0.976663                    0.194363        0.608468                   288.738   305.575\n",
       "    8        0.200025                    0.558539           3.37977    3.88678            0.813882         0.935974                    0.168984        0.777452                   237.977   288.678\n",
       "    9        0.300021                    0.306833           1.91563    3.2298             0.461302         0.777766                    0.191557        0.969009                   91.5631   222.98\n",
       "    10       0.400018                    0.151519           0.29844    2.49702            0.0718673        0.601305                    0.0298431       0.998852                   -70.156   149.702\n",
       "    11       0.500015                    0.0626722          0.0114785  1.99994            0.00276413       0.481604                    0.00114781      1                          -98.8522  99.9939\n",
       "    12       0.600012                    0.0218653          0          1.66663            0                0.401341                    0               1                          -100      66.6633\n",
       "    13       0.700009                    0.00665003         0          1.42855            0                0.344009                    0               1                          -100      42.8553\n",
       "    14       0.800006                    0.000800727        0          1.24999            0                0.30101                     0               1                          -100      24.999\n",
       "    15       0.969903                    3.44813e-06        0          1.03103            0                0.248282                    0               1                          -100      3.10313\n",
       "    16       1                           0                  0          1                  0                0.24081                     0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leyendo los datos\n",
    "datos= h2o.import_file(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",na_strings=[' ?'])\n",
    "myx=['C1', 'C2', 'C3', 'C4', 'C5','C6','C7','C8','C9','C10','C11', 'C12','C13','C14']\n",
    "datos['C15']=datos['C15'].asfactor()\n",
    "myy=\"C15\"\n",
    "model=H2ORandomForestEstimator(ntrees=100,max_depth=20,nfolds=10)\n",
    "model.train(myx, myy, training_frame = datos)\n",
    "y_pred=model.predict(datos)\n",
    "print (y_pred['predict']==datos['C15']).sum()/float(len(datos))\n",
    "model.model_performance(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHHCAYAAACcHAM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/gAAPro1svC2lgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xef36da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "variables = model._model_json['output']['variable_importances']['variable']\n",
    "y_pos = np.arange(len(variables))\n",
    "scaled_importance = model._model_json['output']['variable_importances']['scaled_importance']\n",
    "ax.barh(y_pos, scaled_importance, align='center', color='green', ecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(variables)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Scaled Importance')\n",
    "ax.set_title('Variable Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
