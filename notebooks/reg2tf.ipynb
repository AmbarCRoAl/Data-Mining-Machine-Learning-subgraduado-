{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESMA 4016\n",
    "## Simple Linear Regression using Tensorflow\n",
    "## Edgar Acuna\n",
    "### February 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179000 126500 134500 125000 142000 164000 146000 129000 135000 118500\n",
      " 160000 152000 122500 220000 141000]\n"
     ]
    }
   ],
   "source": [
    "#Entering the data\n",
    "df = pd.read_csv('http://academic.uprm.edu/eacuna/casas.txt',delim_whitespace=True)\n",
    "x=df['area']\n",
    "y=df['precio']\n",
    "x=np.asarray(x)\n",
    "y=np.asarray(y)\n",
    "n=len(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randon seeed for reproducibility \n",
    "np.random.seed(10) \n",
    "tf.set_random_seed(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\") \n",
    "Y = tf.placeholder(\"float\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#W = tf.Variable(np.random.randn(), name = \"W\") \n",
    "W = tf.Variable(tf.ones([1]), name = \"W\") \n",
    "#b = tf.Variable(np.random.randn(), name = \"b\") \n",
    "b = tf.Variable(tf.ones([1]), name = \"b\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .0000001\n",
    "training_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "y_pred = tf.add(tf.multiply(X, W), b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error Cost Function \n",
    "cost = tf.reduce_sum(tf.pow(y_pred-Y, 2))/ (n-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent Optimizer \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables Initializer \n",
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = 713709000.0 W = [74.7304] b = [1.108893]\n",
      "Epoch 100 : cost = 713708000.0 W = [74.73037] b = [1.1828147]\n",
      "Epoch 150 : cost = 713706800.0 W = [74.73034] b = [1.2567364]\n",
      "Epoch 200 : cost = 713706000.0 W = [74.73029] b = [1.3306581]\n",
      "Epoch 250 : cost = 713704770.0 W = [74.730255] b = [1.4045798]\n",
      "Epoch 300 : cost = 713703900.0 W = [74.730225] b = [1.4785014]\n",
      "Epoch 350 : cost = 713702850.0 W = [74.7302] b = [1.5524231]\n",
      "Epoch 400 : cost = 713701700.0 W = [74.730156] b = [1.6263448]\n",
      "Epoch 450 : cost = 713700600.0 W = [74.73011] b = [1.7002665]\n",
      "Epoch 500 : cost = 713699650.0 W = [74.73007] b = [1.7741882]\n",
      "Epoch 550 : cost = 713698560.0 W = [74.73005] b = [1.8481096]\n",
      "Epoch 600 : cost = 713697500.0 W = [74.73001] b = [1.9220302]\n",
      "Epoch 650 : cost = 713696600.0 W = [74.729965] b = [1.9959494]\n",
      "Epoch 700 : cost = 713695400.0 W = [74.729935] b = [2.0698712]\n",
      "Epoch 750 : cost = 713694460.0 W = [74.7299] b = [2.1437929]\n",
      "Epoch 800 : cost = 713693300.0 W = [74.72986] b = [2.2177145]\n",
      "Epoch 850 : cost = 713692400.0 W = [74.72981] b = [2.2916362]\n",
      "Epoch 900 : cost = 713691260.0 W = [74.72979] b = [2.365558]\n",
      "Epoch 950 : cost = 713690400.0 W = [74.72976] b = [2.4394796]\n",
      "Epoch 1000 : cost = 713689400.0 W = [74.72974] b = [2.5134013]\n",
      "Epoch 1050 : cost = 713688640.0 W = [74.729706] b = [2.587323]\n",
      "Epoch 1100 : cost = 713687230.0 W = [74.72966] b = [2.6612446]\n",
      "Epoch 1150 : cost = 713686300.0 W = [74.72962] b = [2.7351663]\n",
      "Epoch 1200 : cost = 713685300.0 W = [74.72959] b = [2.809088]\n",
      "Epoch 1250 : cost = 713684300.0 W = [74.72955] b = [2.8830097]\n",
      "Epoch 1300 : cost = 713683260.0 W = [74.72952] b = [2.9569314]\n",
      "Epoch 1350 : cost = 713682050.0 W = [74.72947] b = [3.030853]\n",
      "Epoch 1400 : cost = 713681200.0 W = [74.72945] b = [3.1047747]\n",
      "Epoch 1450 : cost = 713679800.0 W = [74.72941] b = [3.1786964]\n",
      "Epoch 1500 : cost = 713678850.0 W = [74.72936] b = [3.252618]\n",
      "Epoch 1550 : cost = 713677950.0 W = [74.729324] b = [3.3265398]\n",
      "Epoch 1600 : cost = 713677060.0 W = [74.729294] b = [3.4004614]\n",
      "Epoch 1650 : cost = 713675970.0 W = [74.72928] b = [3.474383]\n",
      "Epoch 1700 : cost = 713674940.0 W = [74.72924] b = [3.5483048]\n",
      "Epoch 1750 : cost = 713673860.0 W = [74.729195] b = [3.6222265]\n",
      "Epoch 1800 : cost = 713672960.0 W = [74.72916] b = [3.6961482]\n",
      "Epoch 1850 : cost = 713671800.0 W = [74.72913] b = [3.7700698]\n",
      "Epoch 1900 : cost = 713670900.0 W = [74.7291] b = [3.8439915]\n",
      "Epoch 1950 : cost = 713669900.0 W = [74.72905] b = [3.9179132]\n",
      "Epoch 2000 : cost = 713668540.0 W = [74.72901] b = [3.9918349]\n",
      "Epoch 2050 : cost = 713667700.0 W = [74.72897] b = [4.065768]\n",
      "Epoch 2100 : cost = 713666560.0 W = [74.728935] b = [4.1397014]\n",
      "Epoch 2150 : cost = 713665660.0 W = [74.72889] b = [4.213635]\n",
      "Epoch 2200 : cost = 713664500.0 W = [74.72887] b = [4.2875686]\n",
      "Epoch 2250 : cost = 713663500.0 W = [74.728836] b = [4.361502]\n",
      "Epoch 2300 : cost = 713662660.0 W = [74.72881] b = [4.435436]\n",
      "Epoch 2350 : cost = 713661700.0 W = [74.72878] b = [4.5093694]\n",
      "Epoch 2400 : cost = 713660600.0 W = [74.72876] b = [4.583303]\n",
      "Epoch 2450 : cost = 713659500.0 W = [74.728714] b = [4.6572366]\n",
      "Epoch 2500 : cost = 713658400.0 W = [74.72868] b = [4.73117]\n",
      "Epoch 2550 : cost = 713657660.0 W = [74.72865] b = [4.805104]\n",
      "Epoch 2600 : cost = 713656450.0 W = [74.728615] b = [4.8790374]\n",
      "Epoch 2650 : cost = 713655400.0 W = [74.72857] b = [4.9529595]\n",
      "Epoch 2700 : cost = 713654460.0 W = [74.72853] b = [5.026872]\n",
      "Epoch 2750 : cost = 713653400.0 W = [74.7285] b = [5.100782]\n",
      "Epoch 2800 : cost = 713652400.0 W = [74.728455] b = [5.1746917]\n",
      "Epoch 2850 : cost = 713651200.0 W = [74.72842] b = [5.2486014]\n",
      "Epoch 2900 : cost = 713650300.0 W = [74.72838] b = [5.322511]\n",
      "Epoch 2950 : cost = 713649100.0 W = [74.728355] b = [5.396421]\n",
      "Epoch 3000 : cost = 713648300.0 W = [74.72832] b = [5.4703307]\n",
      "Epoch 3050 : cost = 713647200.0 W = [74.72829] b = [5.5442405]\n",
      "Epoch 3100 : cost = 713646300.0 W = [74.72825] b = [5.61815]\n",
      "Epoch 3150 : cost = 713644860.0 W = [74.7282] b = [5.69206]\n",
      "Epoch 3200 : cost = 713643900.0 W = [74.728165] b = [5.7659698]\n",
      "Epoch 3250 : cost = 713642940.0 W = [74.728134] b = [5.8398795]\n",
      "Epoch 3300 : cost = 713641900.0 W = [74.7281] b = [5.9137893]\n",
      "Epoch 3350 : cost = 713640960.0 W = [74.72806] b = [5.987699]\n",
      "Epoch 3400 : cost = 713639800.0 W = [74.72801] b = [6.061609]\n",
      "Epoch 3450 : cost = 713638850.0 W = [74.727974] b = [6.1355186]\n",
      "Epoch 3500 : cost = 713637570.0 W = [74.72794] b = [6.2094283]\n",
      "Epoch 3550 : cost = 713636700.0 W = [74.72791] b = [6.283338]\n",
      "Epoch 3600 : cost = 713635700.0 W = [74.727875] b = [6.357248]\n",
      "Epoch 3650 : cost = 713634800.0 W = [74.727844] b = [6.4311576]\n",
      "Epoch 3700 : cost = 713633600.0 W = [74.727806] b = [6.5050673]\n",
      "Epoch 3750 : cost = 713632450.0 W = [74.72777] b = [6.578977]\n",
      "Epoch 3800 : cost = 713631550.0 W = [74.72774] b = [6.652887]\n",
      "Epoch 3850 : cost = 713630660.0 W = [74.7277] b = [6.7267966]\n",
      "Epoch 3900 : cost = 713629400.0 W = [74.72766] b = [6.8007064]\n",
      "Epoch 3950 : cost = 713628500.0 W = [74.72763] b = [6.874616]\n",
      "Epoch 4000 : cost = 713627500.0 W = [74.727585] b = [6.948526]\n",
      "Epoch 4050 : cost = 713626300.0 W = [74.727554] b = [7.0224357]\n",
      "Epoch 4100 : cost = 713625500.0 W = [74.727516] b = [7.0963454]\n",
      "Epoch 4150 : cost = 713624260.0 W = [74.72748] b = [7.170255]\n",
      "Epoch 4200 : cost = 713623360.0 W = [74.72744] b = [7.244165]\n",
      "Epoch 4250 : cost = 713622340.0 W = [74.727425] b = [7.3180747]\n",
      "Epoch 4300 : cost = 713621440.0 W = [74.727394] b = [7.3919845]\n",
      "Epoch 4350 : cost = 713620400.0 W = [74.72736] b = [7.465894]\n",
      "Epoch 4400 : cost = 713619400.0 W = [74.727325] b = [7.539804]\n",
      "Epoch 4450 : cost = 713618240.0 W = [74.72729] b = [7.6137137]\n",
      "Epoch 4500 : cost = 713617200.0 W = [74.72725] b = [7.6876235]\n",
      "Epoch 4550 : cost = 713616300.0 W = [74.7272] b = [7.7615333]\n",
      "Epoch 4600 : cost = 713615040.0 W = [74.727165] b = [7.835443]\n",
      "Epoch 4650 : cost = 713614140.0 W = [74.72713] b = [7.909353]\n",
      "Epoch 4700 : cost = 713612900.0 W = [74.72708] b = [7.9832625]\n",
      "Epoch 4750 : cost = 713611900.0 W = [74.727036] b = [8.057172]\n",
      "Epoch 4800 : cost = 713610750.0 W = [74.727005] b = [8.131082]\n",
      "Epoch 4850 : cost = 713609860.0 W = [74.72698] b = [8.204991]\n",
      "Epoch 4900 : cost = 713608800.0 W = [74.726944] b = [8.278901]\n",
      "Epoch 4950 : cost = 713607800.0 W = [74.726906] b = [8.352811]\n",
      "Epoch 5000 : cost = 713606660.0 W = [74.726875] b = [8.426721]\n"
     ]
    }
   ],
   "source": [
    "# Starting the Tensorflow Session \n",
    "with tf.Session() as sess: \n",
    "      \n",
    "    # Initializing the Variables \n",
    "    sess.run(init) \n",
    "      \n",
    "    # Iterating through all the epochs \n",
    "    for epoch in range(training_epochs): \n",
    "          \n",
    "        # Feeding each data point into the optimizer using Feed Dictionary \n",
    "        for (_x, _y) in zip(x, y): \n",
    "            sess.run(optimizer, feed_dict = {X : _x, Y : _y}) \n",
    "          \n",
    "        # Displaying the result after every 50 epochs \n",
    "        if (epoch + 1) % 50 == 0: \n",
    "            # Calculating the cost a every epoch \n",
    "            c = sess.run(cost, feed_dict = {X : x, Y : y}) \n",
    "            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b)) \n",
    "      \n",
    "    # Storing necessary values to be used outside the Session \n",
    "    training_cost = sess.run(cost, feed_dict ={X: x, Y: y}) \n",
    "    weight = sess.run(W) \n",
    "    bias = sess.run(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost = 713606660.0 Weight = [74.726875] bias = [8.426721] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the predictions \n",
    "predictions = weight*x + bias\n",
    "print(\"Training cost =\", training_cost, \"Weight =\", weight, \"bias =\", bias, '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228672.66515446 119571.4272089  149462.17733097  97153.36461735\n",
      " 149462.17733097 146174.19481754 179352.92745304  89680.67708683\n",
      " 134516.80226994  93267.56710148 151330.3492136  134516.80226994\n",
      "  82207.98955631 224189.05263615 149462.17733097]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
